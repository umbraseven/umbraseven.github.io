---
layout: post
title:  "Linux2.6:进程管理"
date:   2020-05-31 12:50:00 +0800
categories: Linux
tags: Linux 进程 
description: 
---

*  目录
{:toc}

***
## 基本概念

### 进程的定义

关于进程的定义：
>进程是程序执行时的一个实例。<br>
>你可以把它看作充分描述程序已经执行到何种程度的数据结构的汇集。<br>
>从内核观点来看，进程的目的就是担当分配系统资源（cpu时间、内存等）的实体。

我很喜欢看这些定义，作者尽可能做出的抽象化描述。每一个描述都是从某个角度去看它，这些角度都不能完全代表它、表述它，但是有助于我们自己构建出来关于它的理解。


从另外一个角度来说，抽象从来都不是无中生有，而是出自于某种目的而构建、抽象的，计算机是，操作系统是，进程是，虚拟地址空间也是。

对进程而言，我们也可以从多个角度来看它，从内核看，从用户看，从计算机硬件（比如cpu）来看、从数据的角度来看，或者从完全客观存在的实体角度来看等等。


我们需要了解这种抽象吗？需要摁着自己的头，一遍一遍地从不同角度去审视吗？

我想大概是要的，如果你真的想在将来对它进行设计，那几乎是必然需要的。但是这种理解不是纯然基于抽象的，而是要建立在对细节的熟悉上的，只有如此才能把握其内涵与本质，才能做出良好的设计。

***
### 进程描述符

**定义**

>为了管理进程，内核必须对每个进程所做的事情进行清楚的描述。<br>
进程描述符都是task_struct类型结构，它的字段包含了与一个进程相关的所有信息。

这是最简单的一句总结，但似乎也是关于它最重要的。从这个定义出发，就可以理解它包含了什么，如何使用它，它是如何经历变化，为何会成为现在这个样子，以及将来会如何进行扩展。

**描述符**

在linux中，有很多这样的“描述”，我们可以认为page描述符是对一个真实页框的描述，线性区描述符是对一个线性空间段的描述，内存描述符是对一个地址空间的描述，还有文件系统（file、inode、sb、filesystem、io），中断系统（irq、action……）等等。

这种描述是无处不在的。甚至于，似乎就是由各种各样的描述和它们之间的关系、相互作用所组成的。

这样的描述就是抽象。一个进程对象，自然应该包含有和一个进程相关的所有信息。正是因为这些完整的描述/抽象，我们才能将这个异常复杂的操作系统组织起来，在各个层级上进行独立又完整的思考、处理，而不用关心这个层次之外的细节或者实现。

***

**进程描述符包含什么？**

进程描述符里都有什么？或者问，描述一个进程需要什么？

* 进程的基本信息。比如进程状态、断面状态、内核栈地址、父子关系、组、线程、资源统计和限制等等。
* 内存描述符。要包含线性区和页表。前者是对进程虚拟地址空间的管理，后者则是虚拟地址到物理地址的映射关系。
* 文件和终端。（可以抽线地理解为，通过某种io获取的外部信息流。可以使用但是不独占，和其他进程之间有共享和竞争，也可以利用它来通信）
* 信号。（进程之间的通信方式）
* 因为要对进程进行管理而嵌入的各种list_head。（内核对进程的管理，比如在调度过程中对其进行移动之类的）

我想大概就是这么几类。

***
**task_struct与thread_info**

2.6和0.11不同的是，它引入了一个很小的数据结构thread_info，用于放在内核栈页的开始处（因为ts有2.7k大小了，会占据太多的栈空间。之前中断还使用内核栈的时候，就已经将内核栈扩展为两页了，32位系统8kb，64位系统16kb；后来中断使用独立的处理器栈，就又改回来了一页）。

thread_info的第一个字段就是ts，ts的第一个字段是state，第二个字段指向ti。它们都很容易可以利用偏移访问到。

***
**current宏**

在linux0.11中，current是指针；在2.6里，它是一个宏，利用当前的栈位置，将低13位清0，快速得到thread_info地址，然后拿到它内部的第一个long字段。

使用宏的原因是更快。并且在多处理器环境上，它不需要维持一个current数组之类的。

```c
movl 0xffffe000, %ecx
andl esp, %ecx
movl (%ecx), p

```

***
### 进程状态

**状态集：**

* 可运行状态TASK_RUNNING
* 可中断的等待状态 TASK_INTERRUPTIBLE
* 不可中断的等待状态 TASK_UNINTERRUPTIBLE
* 暂停状态 TASK_STOPPED
* 跟踪状态 TASK_TRACED
* 僵死状态 EXIT_ZOBMIE
* 僵死撤销状态 EXIT_DEAD

***
**运行和等待**

以2.6（调度算法为O(1)）为例，来探讨进程的状态变化。

* 进程的自然状态为可运行状态，如果它没有等待某种io资源，没有被杀死或者在调试状态下被跟踪的话。在调度中，进程在新一轮的时间片分配后全部都是active状态，当自己的时间片用完则可能会过期（对非实时、非交互进程），进入过期队列。但是不管是active还是过期，它们都仍然是可运行的。

* 等待状态。等待某个资源而进入睡眠，直到被唤醒。在具体的实现里，我们如何“等待一个资源”？一定有着某个能代表“这个资源已经可用”的条件，直到它变为真，才代表我们等到了。这种条件可能是一个标志位，也可能是一个锁。对非互斥性资源，只要标志位为真，可能就表示我们可以使用该资源了。对互斥资源，可能需要持有某种锁，才能真确地表明我们已经占有它了。

* 很典型的用法里，当我们需要某种资源时，判断其条件，如果为假则进入某个预定的等待队列开始睡眠。在资源的产生/释放函数里，将条件置为真，然后对队列上的进程进行唤醒。

* 可中断和不可中断的区别呢？在windows里，偶尔遇到的在任务管理器里都无法关闭的让你想骂娘的那些卡死了的进程，大概就是不可中断的典型代表了，内核都杀不死它。那我们在什么时候需要用到可中断的等待，什么时候应该用到不可中断的等待？我个人对这些具体应用场景了解得很少，所以没想出来有哪些特别的场景下进程必须等到到某个条件，应该在大多数场景下，还是用前者吧。


***
### task/线程/进程/内核线程

**TASK**

在linux里，很有意思的是，线程和进程并没有那么严格的区分——内核中所有的调度实体都是task，都可以被称为是一个进程。进程非常地轻量，如果这个task不和其他task共享它的地址空间，它就是一个单独的进程，或者被视为“单线程”进程。

而如果task和其他task共享地址空间，文件等资源、进程上下文，那就可以视这些task一起组成了一个“进程”，其中的每个task就相当于其中的线程。

而内核线程其实是永远执行在内核态下的线程，它同样是task，特别的是它没有单独的地址空间（运行在内核空间），所以不需要指向内存描述结构的mm字段，它也不会返回用户态。在linux0.11时并没有内核线程，这是后来加入的（当时的task0/1都运行在用户态）。

进程组和多线程进程不同。进程组只是几个进程聚合在一起，它们之间并不共享地址空间。比如对于管道进程组，它们仅仅是共享管道文件，用来通信。

***
**pid等各种id**

linux的pid数量是有限的，比如32K，恰好是一个页的bits数，可以用位图的方式来表述。但似乎在具体实现里有很多麻烦的地方。

比如linux的多线程进程实现方式里，是通过让一群task共享地址空间来实现的，它们被认为是一个整体的“进程”。那么它们按理应该有着统一的“PID”。但同时呢，每一条线程（都是task）都是可以被linux独立调度的，它们在内核上来看又相对独立。

所以linux定义了各种类型的id：pid、tgid、pgid、sid、tid……

* pid是核心的。每一个task都有一个（注意是task，不是进程），也就是每一个可以被调度的实体都有一个。从另一个角度来说，也就是每个内核级线程都有一个。所以在linux里，tid返回的就是pid。
* tgid，thread group id。线程组id，也就是进程id。一个线程组（进程）的组id，就是领头task的pid。
* pgid，process group id，进程组id。
* sid，session id，会话id。

当我们创建一个进程，如果没有clone_thread标志，那么说明它不与父进程共享地址空间，它是一个独立的子进程。则设置它的tgid为pid，它自己成为一个领头进程，如果之后基于它创建线程，则这个线程组的整体“Pid”就是它的pid。（之所以这么绕，还是因为linux的task模型和通常的线程、进程不太一样……）


***
### 进程组织：链表list_head

链表是最简单的数据结构，事实上它是顺序遍历最适合的结构。因为遍历时间不可能小于O(n)。而链表组织简单，维护容易，插入方便。在linux内核中主要使用的链表是环形双向链表，这样在首尾插入或者查询时灵活性更高。（链表和哈希，加上一些红黑树，组成了内核最重要的数据结构……）

内核提供了一种非常清奇的通用链表实现方式。通常情况下，实现链表的方式是将next/prev指针嵌入到数据结构里，让它变为一个链表；而在linux内核里，是将链表本身嵌入到数据结构里……

大概就是这样：
```c
struct list_head{
    list_head* next;
    list_head* prev;
}

struct student{
    unsigned long nr;
    char *name;
    struct list_head list;
}

```

对数据本身的访问可以通过一个宏来实现：
**container_of(ptr,type,member)**

```c
define container_of(ptr, type, member) ({       \
    typeof((type *)0->member) _mptr = (ptr);    \
    (type*) _mptr - offsetof(type, member);})

define list_entry(ptr, type, member)    \
    container_of(ptr, type, member)

//以上面的sdudent为例，已知某个节点的list指针为lt：

student* st = list_entry(lt, student, list)

```
这种链表在内核里有大量使用。在task_struct结构体中，就包含了不同的6个list_head。比如tasks,run_list,children……

这样的链表可以没有固定的head节点，从任何一个节点开始都可以遍历整个链表，也可以指定任何一个节点为head。当然为了有一个入口，一般都会指定一个指针指向head。

***
**花式操作：init/add/del/move/foreach/safe**

init：因为是环形双向，所以当只有一个元素时，它需要指向自身，这就是init要做的事。

add
```c
void list_add(list_head *tmp, list_head *p){
    tmp->next = p->next;
    tmp->prev = p;
    p->next->prev = tmp;
    p->next = tmp;
}

//内核的实现更有编程美感：
static void __list_add(list_head *new, list_head *prev, list_head *next){
    next->prev = new;
    new->next = next;
    new->prev = prev;
    prev->next = new;
}

void list_add(list_head *new, list_head *head){
    __list_add(new, head, head->next);
}

//实际使用时：

list_add(&stdt2->list, &stdt1->list);

```
链表操作最值得注意的是，它本身的各种倒腾，都不需要改变数据本身的位置，而仅仅是改变其指针的指向。这也是它为什么可以嵌入在数据结构内部的原因。因为不需要它本身移动，也不会改变它本身的布局，所以我们拿着它们内部的list节点，就相当于持有了整个数据结构。

当我们在插入、移动、反转、删除等的时候，实际上内存中没有任何的数据移动，仅仅是改变了一些指针的值。（这和我们直观的“插入”不同，尤其是数组的插入；数组的插入就是会导致数据结构本身发生改变的操作。）

除了这些之后，list还提供了遍历操作，正序、反序，以及安全模式。所谓的safe模式，实际上就是在每一步中都对next指针做缓存，所以在这一步中可以删除掉当前节点，而不用担心会造成list断裂。

遍历操作是用宏实现的，大概是list_for_each()，其实就是将它转化为了for循环的头部。

***
**进程组织：哈希表**

在进程的组织里，另外一种非常重要的数据结构是哈希表。因为我们往往要以一个进程的某种标识为索引来查找它，比如进程的pid，pgid，sid，tgid（进程自己，线程组，进程组，会话）。这是一种典型的map操作，底层实现一般用哈希或者红黑树。（哈希的实现更为简单一点，平均效率更高，而红黑能保证最差结果不太差——随机大法好）

在2.6.11里，就有这四种map方式对应的hash_table。哈希表的实现算法和操作没有什么好说的，一般都是对某个数取模。在这里用的是2^^32的黄金分割数。槽数则一般设定为2047。（注意可以先取模，然后右移多少位，而不是一定要用取模的数作为槽数）

总之，内核是一个非常讲究运行效率的地方，尤其是对一些常用数据的访问和处理。所以在这些数据上，通常的做法都是用空间换时间，用哈希和自平衡树等结构来加速。同时内核有着非常复杂的组织形式，比如对于进程的组织就有各种哈希表，各种链表。

***
### 等待和唤醒

在linux0.11中，等待队列用一种非常初级的方法实现，事实上它就是一个task链表，在其中用tmp隐式地形成一个队列（在这种实现方式里，当尝试wakeup队列时，虽然最终整个队列都会被唤醒，但实际上是顺序的——只有前一个被唤醒，并且被调度时执行后，才能唤醒下一个）。

在2.6.11里，实现方式完全不同了。它同样是基于list_head实现的，但不再只是简单的task链表，而是加入了其他的一些属性字段，比如flag（可以标识是否互斥），wake_function。而且定义了各种操作函数，比如init、add、remove等。

**睡眠完整路径**

第一部分：
* 进程主动调用sleep_on(q)，进入睡眠流程。
* 建立一个wait，将current和default_wakeup_function放进去。
* 将wait加入q。
* 更改自己的state为非0。
* 调用schedule()。
* 在内部调用deactive_task()，触发dequeue()将自己出列，不再存在于runlist中。
* 切换为其他其他进程。

第二部分：
* 某个其他进程调用wake_up(q)，进入唤醒流程。
* 从头到位扫描等待队列q，获得其中的wait，并依次调用try_to_wake_up(wait->task)。
* 在其中，先更改task->state，再调用active_task()。
* 在其中，先recalc_task_prio()，再enqueue()入列，进程再次被加入runlist中。

第三部分：
* 原睡眠进程再次被调度到，从schedule()返回，继续往下执行。
* 将自己移出等待队列。
* 从sleep_on()返回，继续往下执行。

***
**核心数据结构**
```c
//等待队列的元素数据结构是wait_queue_t
struct wait_queue_t{
    unsigned int flags;
    struct task_struct * task;
    wait_queue_func_t func;
    struct list_head task_list;
};

//等待队列头中没有元素，但持有lock
struct __wait_queue_head{
    spinlock_t lock;
    struct list_head task_list;
};
```
注意，
* 等待队列不是基于task->wait_queue之类的构建的，而是重新建立一个wait_queue，把task作为它数据的一部分，而不会用到task内部的链表。

* 事实上，我们可以看到wait_queue的数据有三个：要唤醒的task，标志flag，还有可自定义的唤醒函数func，它的原型大概是：typedef int (* wait_queue_func_t)(wait_queue_t * wait, unsigned mode, int sync, void * key);

* 默认的func，default_wake_function内，做的操作就是调用try_to_wake_up()。

***
**函数族**

在等待/唤醒主题里，有以下几个函数族：
* sleep_on
* wait_evnt
* wait_for_completion
* wake_up
* complete

***
**sleep_on**

sleep_on只睡眠，不关联到任何的等待条件。所以在它的函数体内部，不存在对资源、条件等的循环判断。它的通用形式是：

* 它的参数：sleep_on(wait_queue_head_t * q)

* 建立局部变量wait_queue_t wait。值得特别注意的是，这里用局部变量是ok的，因为sleep_on的执行流程包括了调度和回到调度，在它出去之前的整个周期内（虽然中间会切换到其他进程），局部变量都是有效的。所以在它被其他进程唤醒时，那时候它肯定还在睡眠，也就是还没被调度到，schedule()还没有返回，还在sleep_on()函数体中，自然也有效。

* 调用init_waitqueue_entry(&wait, current)，用current填充wait的属性。在这种默认形式下，flag会设置为0，func会设置为默认的，也就是最后调用try_to_wake_up来唤醒进程。

* 调用__add_wait_queue(q, &wait)，将wait加入等待队列里。注意q是等待队列头（内部不包含实际数据），在里面会调用list_add()，也就是将它插入到队列头部。

* 设置状态为TASK_UNINTERRUPTIBALE；调用schedule()。

* 将wait从等待队列中删除。返回。

sleep_on()是一个函数族。这些等待的函数组主要有三个可选参数：超时（timeout）、互斥（exclusive）、信号（interruptible）。因为sleep_on()不等待资源，所以没有互斥版本，只有超时和信号两个版本。

在具体实现里，信号版本就是将自己的状态设置为TASK_INTERRUPTIBLE，让自己可以被信号唤醒；在超时版本里，就是调用scheule_timeout()，在内部建立定时器。

对于其他函数族里的互斥版本，则是在加入等待队列时，加入到队列尾部而不是头部。而且在wait->flags里，有一个位WQ_FLAG_EXCLUSIVE。这可以在唤醒时用于检查判断该进程对资源的使用是否互斥。

***
**wait_event/wait_for_completion**

它们是同一类型的，都是等待某种资源。可以说wait_event是通用的，而wait_for_completion则是其中的一种形式。

wait_event和sleep_on的不同之处在于，这个等待队列都是等待一个特定的事件——某个condition变为真，所以在内部要进行初始条件判断、循环条件判断，直到有一次醒来后发现条件确实为真了才会退出。

在它内部，几个典型的宏/函数是，DEFINE_WAIT/prepare_to_wait/schedule/finish_wait。之所以要这样设计，是因为在准备等待后（此时已经将自己加入了等待队列，设置了状态），conditon可能发生改变，所以需要再次判断才来进行睡眠。一旦在condition为真时陷入睡眠，可能就再也没有醒过来的机会了。

这个里面似乎有一个比较绕的竞争隐患——我在睡眠时肯定是不能持有condition的锁的，否则别人会无法写，来唤醒我；那我如何保证在自己睡眠的一瞬间，没有人抢占、将它改写掉呢？

初始化宏的用法也很清奇：

```C
#define DEFINE_WAIT(name)                        \
    wait_queue_t name = {                        \
        .task        = current,                \
        .func        = autoremove_wake_function,        \
        .task_list    = {    .next = &(name).task_list,    \
                    .prev = &(name).task_list,    \
                },                    \
    }
```

wait_for_completion系列函数，则引入了一个数据结构struct completion{ unsigned int done; wait_queue_head_t wait)。它只是event的一种特殊形式，它的等待形式里只有信号一个版本，也就是一定要等到，没有timeout，而资源也一定是互斥的。

在用complete将它唤醒时，也只有两种选择：唤醒一个，或者唤醒全部。对于wait_event，则可以用数不胜数的wake_up族，进行花式唤醒，基本上能想到的都可以找到。

***
**wake_up/complete**

complete专门用来唤醒completion，是互斥资源；wake_up则是通用的，实际上在complete底层同样调用了__wake_up_common()。只是wake_up实在是花样繁多。基本形式是：

```
__wake_up_common(wait_queue_head_t * q, unsigned int mode, int nr_exclusive, int sync, void * key)。
```
所以唤醒总是针对某个等待队列，而非某个进程的。在等待体系的组织里，进程和最终唤醒的方法都是保存在等待队列中的元素里。mode是区分线程/进程的，nr则表示要唤醒多少个互斥进程，当为0时全部唤醒；sync为1时则表示waker马上就会进行调度，所以wakee可以考虑不抢占，这样就有更大的机会让它们俩在同一个cpu上执行，这种在关联进程中会很有效，有效提升cash命中率。

（自己写一遍：）
```C
static void __wake_up_common(wait_queue_head_t * q, unsigned int mode,
                     int nr_exclusive, int sync, void * key)
{
    struct list_head *tmp, *next;
    list_for_each_safe(tmp, next, &q->task_list){
        wait_queue_t *curr;
        unsighed flags;
        curr = list_entry(tmp, wait_queue_t, task_list);
        flags = curr.flags;
        if (curr->func(curr, mode, sync, key) &&
                (flags & WQ_FLAG_EXCLUSIVE) &&
                !--nr_exclusive)
            break;
    }
}

```

从这个例子里也可以看出嵌入链表的有趣之处：头部和元素的数据结构形式竟然还可以不一样。头部中没有data，但持有lock；元素中有data，但不管lock。

这个系列还有着大量的类似函数，比如对于互斥进程就有不同的add操作。值得注意的是，互斥进程和非互斥进程（它们的区别是对于资源是否需要独占）可以放在同一个队列里，因为wakeup时总是从头往后扫描，所以非互斥进程总是插入队列头部，互斥进程总是插入到队列尾部。当资源空闲时，从头到尾扫描，直到某个互斥进程被有效唤醒，才会停止唤醒（此时所有的非互斥进程都已经被唤醒了）。


***
### 如何组织进程？

从内核组织的角度来看，进程会存在于哪些位置？

讨论这个问题也挺有意思的。因为从程序员来看，进程描述符总是存在于内存里，但是从内核来看，只有可以通过某种路径找到它，才能有效管理它，这个路径才是它的位置。（在linux0.11中，会有一个整体的task数组，所有的进程都可以用遍历数组的方式访问到，但是2.6已经没有这样的大数组了，它实际上散布在内核空间中）

进程的“内核视角位置”是和它的状态密切相关的：

* 对于running进程，它会存在于runqueue中，在active/expired两个array之一。调度系统可以轻松访问到它。
* 对于等待进程，则会存在于等待队列。等待队列并不由调度子系统管理，而是由等待队列所期待的资源的相关模块进行管理，比如等待io的队列会由io的中断函数里进行唤醒。唤醒之后会将其加入到调度队列里，又重新被内核管理。
* 暂停和僵死进程呢？似乎没有专门的数据结构，而是通过pid、父子关系来访问。

***
### 资源限制等其他

**资源限制**

内核会对进程资源进行一定的限制，比如cpu时间、内存、文件大小、锁、页框、堆、栈等等。限制的方式是定义一个数组：
struct rlim{
    unsigned long curr;
    unsigned long max;
}
rlim[] rlims; 
其中每一项就代表一个限制。大概就是这样。这个数组会在task_struct里，fork时子进程会继承父进程。
***
**与调度相关的系统调用**

比如更改自己的优先级，设置其他进程的优先级，设置调度策略（比如设置为实时进程），设置cpu亲和力掩码等等。大部分设置操作都需要superuser权限。

都比较简单。

***
## 进程切换：switch_to()

### 上下文切换

在linux0.11中，进程切换包括几个部分：内存切换（通过ldt段base的不同，指向不同的页目录项），硬件上下文切换（通过ljmp触发tss切换）。

在linux2.6中，调度程序schedule()会在找到合适的进程后调用contex_switch()，主要内容也是切换进程的状态：虚拟地址空间和硬件上下文。虚拟地址空间的切换是通过调用switch_mm()完成的，硬件上下文切换中则调用switch_to宏。

switch_to的实现是和具体的cpu架构密切相关的，我们在这里主要讨论经典的x86架构下它的实现。在2.6中，上下文的切换不再是依靠一个长指令，而是通过一系列的mov操作完成（这类似于从硬件变成了软件），它的效率竟然和原来的也差不多，而且还有优化空间（原因可能是那个长指令无法进行流水线优化）。

在2.6中，所有的进程切换都是发生在内核态。（还记得在0.11里，进程的第一次执行可能会直接切换到用户态？而2.6里，fork出的新进程会返回到ret_from_fork位置。）用户态的所有寄存器状态都保存在内核栈里，会在从系统调用/中断返回时恢复，而内核态持有的私有变量是非常少的。

典型的情况下，只需要恢复esp/eip就足够了。内核态所有进程的ss/cs都是固定的（注意不再是0.11的0x10/0x08），不需要切换；eflags需要保存和恢复；ds和es则看情况；另外还有一些浮点数处理单元、io位图之类的可能要保存。总之不再像0.11中要保存所有的寄存器状态了。

在0.11中，所有的寄存器都被“断面拍照”，存入tss；2.6里，不再切换tss，甚至于进程不再持有tss这个数据结构了。每个进程都会有自己的thread结构，其中有esp0等信息；而tss是一个cpu持有一个，在切换进程时，将next进程的esp0写入即可。

***
**code**

swtich_to的核心代码实际上是非常少的：
```c
//linux2.6.11/include/asm-i386/system.h
#define switch_to(prev,next,last) do {                    \
    unsigned long esi,edi;                        \
    asm volatile("pushfl\n\t"                    \
             "pushl %%ebp\n\t"                    \
             "movl %%esp,%0\n\t"    /* save ESP */        \
             "movl %5,%%esp\n\t"    /* restore ESP */    \
             "movl $1f,%1\n\t"        /* save EIP */        \
             "pushl %6\n\t"        /* restore EIP */    \
             "jmp __switch_to\n"                \
             "1:\t"                        \
             "popl %%ebp\n\t"                    \
             "popfl"                        \
             :"=m" (prev->thread.esp),"=m" (prev->thread.eip),    \
              "=a" (last),"=S" (esi),"=D" (edi)            \
             :"m" (next->thread.esp),"m" (next->thread.eip),    \
              "2" (prev), "d" (next));                \
} while (0)
```

***
### 内联汇编

关于代码本身，有一些地方值得讨论，比如do{} while(0)的宏编写模式，但是这里想着重讨论的还是内联汇编。这是一个可读性很差的内联代码，能读懂它，就能读懂大多数的内联汇编代码了。

内联汇编难懂的部分就在于它的input/output变量上面，我自己的理解大概是这样：
* 对于input变量，相当于函数的参数输入，会在执行代码部分前初始化完成。但需要特别注意的是，输入是可以指定存储位置的，比如指定寄存器，或者内存里。对这些变量的访问，可以通过%num访问到；如果指定了寄存器，则可以直接使用寄存器里的值，不一定要通过%num的形式了。

* 在这个例子里，next->thread.esp和next->thread.eip都是存放在内存里（用m标示），则只能通过%5和%6访问；prev则存放在eax里（2表示和%2放在同一个位置，也就是output的last），可以直接使用；next存放在edx，也可以直接使用。我们可以看到，在之后调用__switch_to()函数时，没有压入参数，这就是因为fastcall中默认的前两个参数就是保存在eax/edx中，而c函数__switch_to()声明为了fastcall，直接从寄存器取参数，而不是栈。

* 对于output的处理是类似的，如果对输出变量指定了寄存器，那就会自动完成赋值，比如在执行完成后，会将eax赋值给last，将esi/edi中的值，赋值给局部变量esi/edi。对于没有指定寄存器的变量，则需要显示写入，比如prev->thread.esp/prev->thread.eip，在代码中可以通过%0和%1引用。

* 我觉得主要的阅读难点就在于输入输出变量的自动处理和手动处理，弄明白了这个其他的就好理解。

***
### 切换过程：

大致的过程如下：
* 将prev/next装入eax/edx；将eflags/ebx入栈保存。
* 将此时的esp保存到prev->thread.esp字段；将next->thread.esp载入到esp，完成内核栈的切换。
* 将标号为“1”的地址保存到prev->thread.eip字段；将next->thread.eip压入栈中。
* jump至c函数__switch_to()；
* 标号1：从栈中弹出ebx/eflags。
* 将eax赋值给last。

其中有很多有意思的点——

***
### esp的切换

当我们把next->thread.esp载入到esp寄存器时，实际上就已经完成了进程的切换——虽然执行的代码一样，但是状态已经发生了变化，此时的硬件上下文是基于next的了，通过内核栈地址偏移拿到的current也是next进程了。而后我们只是在switch c函数中，将自己的某些字段写入gdt中的tss/lds项了。

我们可能会疑惑，切换一下栈，就意味着进程切换了，如此简单？是的，就是如此简单。这依赖于一些前提：同时运行在内核空间，所以对于任何的内核控制路径，页表、段寄存器什么的都是共用的，一致的。所以，区别出内核控制路径的是什么？就是栈的地址，而其他的一些必须状态，都可以从栈上恢复。比如ebp/eflags/eip。

***
### eip切换

**利用ret实现跳转导向**

eip切换是理解switch_to宏的难点。

当我们需要切换eip，从prev进程切换到next进程时，毫无疑问必须有一次jump跳跃。但是这种跳跃可以用一种更加有趣的方式实现：通过函数返回时，ret的自动跳转。

之所以可以这样，是因为每一次从prev切换到next，前段的处理流程是通用的——next会保存prev的一些状态，载入自己的……做完这些之后，再跳转到自己的处理逻辑里去。

这个通用的处理过程就是__switch_to()，我们只需要改变后面跳转的目的地址，就能导向不同的处理逻辑。这个地址就是我们save/restore的eip。所以restore的方式是push，然后jump……

***
**两种路径**

eip切换的一个细节是，调用__switch_to()时用的jmp而非call，为什么？因为虽然在大多数时候，我们都是返回到标号1，但是某些时候不是。

什么时候不是？所有经过schedule()-switch()进来的，肯定都是1，因为我们就是这样保存的，而我们平时常见的各种进程暂停方式，不管是直接调用还是延迟调用，不管是被中断打断，还是自己放弃，最终都是调用了schedule()，只有一种情况例外，那就是新fork的进程，x它的“断面”不是自然切出来的，而是由父进程手动设置的。父进程把它设置成了，“可以被调度”的样子。

在linux0.11里，这个返回点直接在用户态，也就是程序入口；在linux2.6里，这个返回点是ret_from_fork。所以在这种情况下，如果我们是用call调用的__switch_to()，那就不行。

事实上，执行是没有问题的，我们可以想象一下整个流程：切换到一个新进程，切换esp到它的内核栈，调用__switch_to()之后返回到标号1，然后继续往下执行，直到函数contex_switch()执行完毕，触发ret，但此时新进程内核栈顶并没有保存一个适当的返回地址，导致出错。

而正确的方式可能是这样：切换到一个新进程，切换esp到它的内核栈，压入ret_from_fork，jump至__switch_to()之后通过ret返回到ret_from_fork，然后继续往下执行，通过某种方式返回到用户态，内核栈反正肯定已经早就被布置好了。

对于其他进程呢，直接call可以吗？应该是可以的。事实上，call就是执行的压入标号1地址，jump，这两个操作。而对于所有进程，它们共享内核代码段，标号1的地址都是一样的。

***
**从标号1开始**

除了新fork的进程之外，大家都是跳转到了标号1？那怎么可以认为完成了处理流程的切换呢？

虽然大家都是从标号1开始，但是不同的进程，esp指向了不同的内核栈。而在内核栈中，内容各不相同。当我们利用iret返回时，就导向了不同的处理流。比如有的进程潜逃了内核控制路径，一次iret仍然停留在内核态，有的则通过它返回了用户态……

内核代码是被所有进程所共享的，而一个控制路径，实际上是由代码（状态转移函数）和栈数据（当前状态）共同决定的。一条控制路径的切换，完全可以只切换esp，而让eip继续沿着共享代码往前，在前方再因为esp的数据不同而分叉……

***
### 两种视角：cpu与内核/进程

在switch_to中，如果切换esp象征着已经完成了进程的切换，可以看到我们仍然可以改写prev的值。这当然很正常，在内核代码里可以更改任意进程的状态。

我想讨论的是背后的视角——cpu与内核的视角，以及进程的视角。

如果通过cpu的视角来看，cpu的运行无疑是连续的，甚至于它根本分辨不出来哪条指令是属于哪个进程。而在内核来看，整个计算机的运行同样是连续的，虽然其中的进程不断被冻结和恢复，进程本身是离散的，但计算机整体是连续的。

在一个switch里，所展现的就是这种连续性。

而如果我们从进程的视角来看呢？进程实际上是中断和恢复的，但它会以为自己是连续的。从一个进程被中断和恢复的过程来看：
* 它被cpu抛弃，成为了prev；它进入了swtich，保存了自己的eflags/ebp到栈上，将esp保存到字段里。然后它就被冻结了。
* 从它被冻结的位置，它苏醒了。此时它成为了next，而新的prev刚刚也正保存了自己的eflags/ebp/esp，并且通过一条优美的mov操作切换了内核栈。这一睡一醒之间，prev和next已经完全不同。
* 它醒来的第一件事，是将prev的eip帮它保存好，然后将自己的eip入栈。（为什么要这样设计？为什么不能自己在睡眠之前保存自己的，在切换栈之前保存？我想没什么原因……毕竟在内核来看，我管你什么prev/next视角，只要有个后门能让我塞地址就行了）再调用__switch_to()去载入一些属于自己的状态，最后通过ret返回到执行流里继续往下。

所以，有趣的是，进入switch_to的，永远是prev；而执行内部__switch_to的，永远是next。

***
**prev和last**

这是一个在变迁中被保护的量——eax和其他寄存器不一样的是，它在switch中似乎不被魔法所影响，而能够穿过去，保留自己的值。

所以一个进程作为prev进入swtich时，eax保存的是prev自己的值；而当它在其中醒来时，它已经成为了next，eax中保存的则是这一次进入switch中的prev，已经不再是自己了。

所以在调用的时候传入的是switch(A,B,A)，出来的时候，last已经成为了某个C。

***
**浮点数处理器**

在内核编程忠告中有醒目的一条：不要使用浮点数。原因就是浮点数的计算在硬件上很麻烦，它是用特殊的浮点数单元进行处理的。而且其中可能还包含有用户态的计算状态。

所以在内核中尽量不要使用，效率低不说，容易出各种问题。

在进程切换时同样要考虑到它的上下文。具体就不展开了。


***
## 进程的创建和终止

### do_fork()

执行流程很长，详情可以参考书本，它的主要工作都是通过调用子函数copy_process()完成的。我们只从整体上来理解一下。

这个函数是进程创建的真正干活的，clone/fork/vfork都依赖于它，只是会传入不同的参数。比如用clone来建立共享页表（地址空间）的线程；用vfork来让父进程等待子进程的执行完成等等。

创建一个进程需要什么？

创建一个进程，就是创建出来一个可以被调度的实体。这个实体被定义为进程，它的描述符就是进程数据结构ts。我们要做的事情，就是完善ts中各种字段属性，让其真实有效，从而让下次调度到它时，可以流畅、自洽地往下执行。

虽然版本从linux0.11到了linux2.6，代码数量发生了几个数量级的变化，内核框架变得复杂很多，但是从抽象上来看，进程所需要持有的状态仍然是那些——地址空间（页表）、硬件上下文、信号、文件等。还有很多和进程管理、调度相关的属性，比如优先级、时间、各种链表、id、锁……

现在的ts大概有一两百个字段，其中估计有一半可以沿用父进程的，一半得重新设置吧。

***
### 新进程的栈：stack/esp

在fork中，很有意思的是栈和esp的值。对于新fork的进程p，我们需要设定三个esp：p->thread.esp, p->thread.esp0, childregs.esp。
```c
    childregs = ((struct pt_regs *) (THREAD_SIZE + (unsigned long) p->thread_info)) - 1;
    *childregs = *regs;
    childregs->eax = 0;
    childregs->esp = esp;

    p->thread.esp = (unsigned long) childregs;
    p->thread.esp0 = (unsigned long) (childregs+1);

    p->thread.eip = (unsigned long) ret_from_fork;
```

childregs是复制父进程传过来的regs，它实际上就是保存在父进程内核栈中的，进程用户态的各种寄存器数据。childregs需要保存在子进程自己的内核栈上，所以它的定位也很有意思。这里尤其要注意的是后面的“-1”，它不是减1B或者一个指针长度，而是减去了整个regs大小。

所以childregs就是位于内核栈顶，此时的栈里存放了一个完整的regs，栈顶指针就是从初始位置向下regs，也就是childregs。所以有p->thread.esp = childregs。这也是子进程被调度后的内核栈开始位置。

而esp0则是内核栈初始位置，在之后经过每一次陷入内核时，都会从这里开始。

而childregs.esp，则是用户栈地址。对于普通的进程fork，因为不共享页表，所以直接传入regs.esp，让父子进程的用户栈地址重叠，之后再触发写时复制区分开就可以。但是对于线程创建clone，因为共享页表（这意味着不会增加page的引用次数，每个进程都可以直接读写，而不会触发写时复制保护），所以必须让父子进程的用户堆栈位于不同的位置。此时传入的是newsp，是在regs.ebx携带的，作为clone系统调用的参数之一传进来的。


***
### Child-do-first

这是个很有意思的机制，当父进程fork出一个子进程时，如果两者在同一个cpu上，且不共享页表（CLONE_VM标志为0，如果是创建线程，则需要共享页表），那么我们应该让子进程先运行。原因是，进程的创建运用了写时复制机制，如果是父进程先运行，那它所有的写操作都会导致页面的copy，这在底层会导致申请新的物理页，更改页表等等，很麻烦；而如果是子进程先运行呢？很多情况下，它都是要调用exec载入一个新程序的，此时它会放弃掉整个页表结构，申请一个新的，这也就意味着它不会触发写时复制了。而如果在这之前父进程先执行，那付出的写时复制操作都是白给。

那我们如何实现呢？

非常简单：
```c
p->prio = current->prio;
list_add_tail(&p->run_list, &current->run_list);
p->array = current->array;
p->array->nr_active++;
rq->nr_running++;
set_need_resched();
```
初看可能会疑惑，这不是增加到tail了吗？如果我们将current->run_list视为链表头，那么add_to_tail其实就是插入到它的前面……而在常规操作之下，当我们调用__active_task(p,rq)时，则根据p->prio，寻找到rq->active中对应的runlist，同样调用list_add_tail，但是这样就是真正插入到队列的最后面了，也就是会在父进程之后执行。

***
### 内核线程

**内核线程**

内核线程实际上也是一个进程，但是它不会返回用户态，也没有属于自己的页表结构，而是与所有的内核线程共享，所以它看起来“像”是一个线程。重要的是，它也是一个调度实体。

内核线程会辅助完成一些内核的工作，比如buffer、socket、frame等等的管理。（这些工作的一个共同点就是它们提供了某种抽象，而且本身资源是有限的，而它们的运行又是独立于任何进程的）

实际上这些工作也可以线性完成，比如当内核在某个进程触发pagefault，需要空的物理页，发现没有，然后就触发一次页框的同步，将可以换出去页一次性换出去一大批，但毫无疑问，这种方式效率不高，而且可能导致系统响应变差。反过来，我们将它放置在后台，有空的时候就跑一跑，维护资源的充足，显然会更好。

（似乎有一个隐含的问题：这些内核进程的优先级应该如何设置？应该是不高的，那如果负载比较重的话，是否会导致它们失去执行机会，让资源回收效率变低呢？动态调整？）

创建内核线程同样是通过调用do_fork()完成的，传入的标志会比较特殊而已，比如start_stack为0，表示没有用户栈。

我们创建子进程时，一般会通过在之后调用exec()载入一个新的程序映像，那内核线程呢？

内核线程是通过传入需要执行的函数fn和它的参数args，将它们都放入到内核栈里，也就是regs里。同时，将regs.eip修改为一个特定的内核代码地址kernel_thread_helper，看名字就知道，它的作用就是帮助内核线程动起来的。它做的工作也很简单，将args入栈，调用fn，之后再调用do_exit()退出。

***
**进程0和进程1**

进程0:完全的手动构建，从无到有的过程。

进程1:通过调用kernel_thread()创建的内核线程，传入的fn是init。照着进程0的模板构建的。


进程0有信仰之跃的过程吗？没有。它不需要进入用户态（linux0.11中，会通过一次跳跃变为用户态，所以更有“进程”的感觉）。

它是一个进程吗？进程需要什么？基于页表的地址空间（它有），内核栈（它有），进程的父子亲属关系（它是根），信号文件等（它全有）。所以我们应该如何界定它呢？它天生就是内核的初始控制路径，甚至是唯一的。它当然可以被认为是一个进程。只是在完成各种任务后，它进入了cpu_idle()循环。

当然在它的执行过程里，应该是有一些限制的。比如在内存管理得到初始化之前，申请一页物理内存大概是不允许的。但是它应该也不需要申请，因为它运行所需要的各种资源，都是手动构建、作为静态变量写好的(大概位于bss区和data区？)，比如init_mm\init_fs等，都是由INIT_MM/INIT_FS等宏手动初始化好的。从进程1开始则是完全不一样的，进入了正常的进程创建流程。

***
### 进程的撤销和终止

进程撤销虽然有各种各样的情况，比如自己调用exit()（这会被插入到main()函数的最后面），或者被KILL信号杀死，或者发生一个没得救的cpu异常后，在异常处理中被杀死。

但是这些情况最终都是在这个进程的上下文里调用了do_exit()。它做的事情和fork正好相反，将fork出的各种数据结构、资源全部释放掉，它也是围绕ts为中心（事实上，我们可以将ts看做是进程各种资源的入口），然后一顿操作，将除了ts和ti之外的资源全部清理掉，比较典型的方式是，put各种资源的引用数，如果为0了就释放掉；最后再把自己的数据结构占用的内存也释放掉。

当然其中还包括各种进程关系的处理，因为进程在很多个list里。要挨个都把自己删除掉（因为是双向环形表，还有一个固定的head，这很容易就完成了）。还有就是要通知到位，告诉那些和自己相关的进程，比如兄弟、父子之类的。

最后就是设置自己的状态，等到父进程读取自己的退出状态，回收掉最后的ts、ti数据结构。进程从此彻底消失。


***

## 进程调度：O(1)

### 调度策略

**关于调度**
在漫长的linux时代（0.11-2.4），调度都是用的O(n)算法：在每一次调度中，重新计算每一个可运行进程的时间片和优先级，这需要扫描整个runlist，耗费时间很长。它的优点是简单易懂，缺点则是效率太低，尤其当对实时性有较高要求的时候。

调度策略本身就是一个很复杂的事，它的需求是两方面的：首先是能够提供一个好的调度结果；其次是调度行为本身要高效。

对于第一项，有一系列的、相互冲突的需求，比如响应时间、吞吐量、公平……对于第二项，最重要的是足够快，其次是足够简单，多占点内存反而没关系。前者一般是策略相关的，后者则是算法相关的。当然两者是互相影响的——决定一个策略是否可行的，除了策略本身之外，还依赖于是否有良好的算法实现。

**O(1)**

O(1)是个非常好的作品。

它的基本策略是，将进程划分为三类：实时进程、交互进程、批处理进程。对于实时进程，可以在运行时标记，采用单独的调度策略；对于交互进程和批处理进程，则在进程运行中，根据它们的表现进行判断，而不是预先设定。

不同的进程有不同的需求，实时进程需要的是严格的响应时间；交互进程需要的是一定的响应时间以提高交互体验；批处理进程则是吞吐量。同时又要保证每一个进程都能在一定时间段内得到执行，不会出现饥饿；还要注意不让某个进程突然占用掉太长的时间，使得其他进程的体验变差……

如何缩短一个进程的响应时间？首先，毫无疑问，这决定于计算机的状态，负载越高竞争越强，响应越慢，这是无法避免的。所以我们需要解决的实际上是，在不同的优先级上，怎么保证进程的响应时间——比如在没有其他同等级或者更高等级的实时进程竞争的情况下，如何保证实时进程的响应速度？对于交互进程，如何在批处理进程的竞争下保持良好的交互体验？

最直观的就是优先级。让对响应时间有更高需求的进程拥有更高的优先级，并且允许内核进行抢占——这样，一旦高优先级的进程进入运行队列，它就可以在最短的时间里得到执行。比如交互进程总是会抢占批处理进程。

那如何分配时间片呢？不设任何限制，从高优先级一路往下？实时进程的FIFO模式就是这样的，先到先执行，直到它自己放弃cpu；实时进程的RR则类似，它有时间片，但每次用完后都会恢复，自己一直保存在runlist里，它让同优先级的进程可以得到插队的机会，但低优先级的就只能等。但是这种方式肯定是不合适普通进程的，它会导致饥饿，一个恶意的进程可以一直霸占着cpu。

那如何设定时间片的长短？和优先级有什么样的对应关系？可以和优先级正相关，也就是优先级越高，时间片越长。O(1)就是这样做的。

当然这样做也有很多可以被诟病的地方，比如批处理任务实际上需要大量的cpu运算，它最好的方式就是长时间运行不受打扰，但是现在它能分到的时间片都很短。而交互进程虽然它对于响应速度要求很高，但实际上需要的计算是比较少的，但却给了它一个很长的时间片……

还有一个问题是，当时间片用完之后，进程要过期吗？实时进程是永不过期的，那普通进程呢？如果一个高优先级的交互进程在第一次执行完就过期了，那要等到其他所有的进程都执行完有调度机会，这个响应时间会有多长？

O(1)采用的策略是，不一定过期。如果判定为交互进程，而且已经过期的进程里没有优先级比它还高的，且它们没有等太久，就不把它置位过期，但是可能会降低优先级来处理。等到所有的进程都过期了，就开始一轮新的循环。这也是为什么低优先级进程不能持有太长时间片的原因，这会导致一轮循环的等待时间过长。

对于交互进程，在一轮时间片里是可能被多次执行的。比如在时间片还没用完时就陷入了用户交互的IO等待中，此时进程的状态会变为TASK_UNINTERRUPIBLE而不再是TASK_RUNNING，会从runlist移出，但它的时间片会保留，且会记录各种时间戳信息。等到它重新active，会被再次移入runlist。此时可能还是同一轮循环，但也可能已经是新的一轮循环了。

这个其中的响应时间其实就是它被唤醒，到它得到调度的时间。

因为我们需要动态地分辨交互进程和批处理进程，所以也会有动态优先级的设计。它是根据进程的过往表现（核心是睡眠时间和运行时间），来判断进程的交互程度，从而在它的静态优先级上进行一定程度的调整。在linux2.6.11里，普通进程的优先级是从100-139，动态优先级的调整范围是±5，但不会越线。

动态调整、交互进程判定、优先级的重新计算等等，其中的具体逻辑是比较繁琐复杂的，会根据当前进程的静态优先级、权重之类的综合来计算。不深究。

同时为了防止一个进程因为睡得多，优先级升高，有太长的时间片，会在上面做各种限制，比如将太长的时间片进行打断，一旦发现它执行时间超过某个限值，就强迫它重新入列，并调度一次，这至少会让同优先级进程得到插队的机会。（注意这不会使它出列，所以同等级其他的执行完了还是要轮到它）

***

### O(1)算法

O(1)算法就是要在O(1)时间里实现上述的调度策略。它需要在以下几个动作中都做到O(1)：每个时钟tick里，对进程状态的更新；调度里，找到next进程；进程的入列操作。

从这个需求出发，我们可以寻找合适的数据结构。

事实上，找到next往往是简单的，我们只要维护数据是有序的，让next保持在队列头部，每次都直接从头部拿就好了。所以我们进程的基础组织应该是队列形式的，符合FIFO原则，而且不能用数组实现，最好是最简单的链表。

要维持数据有序，就需要在入列时将其插入到合适的位置，维持next的正确性。因为有不同的优先级，我们需要插入到不同的位置，如果所有进程都串在一根大链表上，那为了寻找合适的插入点，我们不得不遍历链表，比较prio。

所以我们必须维持多个链表，每个优先级对应一个。这样在插入时才能直接根据进程的prio，选择合适的链表，插入到队尾。“选择合适的链表”，这是一个随机访问操作，所以链表必须放在数组里。也就是说对于140个优先级，应该有一个list_array[MAX_PRIO]，直接通过list_array[prio]来访问。
>list_add_tail(p, list_array[p->prio])

这样就会产生一个问题，当我们找next的时候，如何确定到哪个prio里找呢？如果挨个查看是否有可运行的进程，那就是O(m)而不是O(1)了。

解决的办法是建立一个位图，如果某个优先级的runlist里有进程，该位就置1；而cpu有指令可以迅速找到第一个为1的位。所以找到next就变成了：
>next = list_array[get_first_bit(bitmap)]->next 

还有一个问题是，如何处理过期循环问题？在原始的O(n)方式中，在所有进程都过期后，再根据优先级计算时间片，再放入到runlist里。但这个处理毫无疑问是O(n)的。在每一次的tick或者schedule里，实时处理当下进程p？比如当它的time_slice减为0的时候，重置它的时间片和优先级？但是它无法重新加入runlist啊，它必须出列。

解决的方法是维护两个list_array，分别是active_array和expired_array，一个进程不管是active还是expired，都维持它的正确、有序，而不用集中处理——当active_array为空时，就交换这两个array。

从这个算法的实现里，我们可以感觉到一些计算机算法的有意思的点，比如这个算法就是典型的用空间换时间，通过维护大量复杂的数据结构，来提高算法查找、插入的效率。比如在设计时，分散处理比集中处理更好，虽然它们所使用的时间总和是一样的，因为它会影响到最大延迟时间，而在计算机里，这种“界限”非常重要。

某些实时系统，就是需要我们能“保证”不会跃过某些“界限”。

***
### 核心数据结构

核心数据结构有三：

* runqueue：rq，运行队列。
* prio_array：array，链表数组。
* tast_struct：task/p，进程描述符

它们的关系大概是，
* rq中包含两个prio_array，轮流当active/expired。实现方式也很简单，维持一个prio_array[2]数组，维持两个指针active/expired，控制它们的指向就行。
* array：包含bitmap[max_prio]、queue[max_prio]、nr_active。
* task：task->array，task->run_list。

典型的入列出列操作：
```c
void active_task(task_t* p, run_queue_t * rq)
{
    //其他的操作，比如recalc_task_prio()等
    enqueue_task(p, rq->active);
    rq->nr_running++;
}

void enqueue_task(task_t* p, prio_array_t* array)
{
    list_add_tail(&p->run_list, array->queue+p->prio);
    set_bit(p->prio, array->bitmap);
    array->nr_active++;
    p->array = array;
}

void deactive_task(task_t* p, run_queue_t* rq)
{
    rq->nr_running--;
    dequeue_task(p, rq->active);
    p->array = null;
}

void dequeue_task(task_t* p, prio_array* array)
{
    array->nr_active--;
    list_del(&p->run_list);
    if(list_empty(array->queue+p->prio))
        clear_bit(p->prio, array->bitmap)
}
    
```
其中有很多值得学习的细节，比如：
* active_task和enqueue_task分开；
* nr_running/nr_active在入和出时的更新时间点，先入列，再增加nr；先减nr，再出列。这是资源使用时很好的习惯，避免竞争。

runqueue中，实际上还包含有大量的进程调度管理字段。我们对它进行讨论。
* 如果启用了SMP，每个cpu都有自己的运行队列。进程也有自己的字段task->cpu。事实上，如何拿到当前cpu的cpu号？就是听过current->cpu。不同的cpu之间可以有多种交互，它们虽然运行不同的进程，但是它们处于一个内核空间，自然也就可以读写对方的rq，当然这需要持有锁，防止数据竞争。

* nr_running，注意它和nr_active不同。前者表示真正的可执行进程数量，后者则表示未过期的进程数量。前者包含active_array和expired_array，后者只包含当前的active_array。

* nr_uninterruptible，之前在运行队列而现在进入不可中断睡眠的进程。因为它们醒来后会回到原来的cpu，所以它表征了未来的可能负载变化。·

* cpu_load/active_balance，cpu负载因子/均衡标志，在cpu负载均衡时会使用到。

* expired_timestamp/best_expired_prio，过期进程最老时间戳/过期进程最高优先级，这会用于交互进程的过期判断。

* curr/idle，本地cpu的正在运行/swapper进程描述符指针。

* prev_mm，进程切换期间prev的内存描述父，因为某些时候需要共享页表。

***
### 主要函数

主要函数有：
schedule_tick()
try_to_wake_up()
recalc_task_prio()
schedule()
load_balance()

**schedule_tick()**

这是每个时钟滴答中都会调用的关于调度的处理。其中做的主要工作有：
* 空闲处理。如果当下运行的是idle进程，则总是检查是否有新的可运行进程加入，如果有就执行延迟调度。
* 递减时间片。需要根据进程类型进行不同的处理，比如对于实时进程/普通进程就有不同的处理方式；如果时间片递减为0了，还要做进一步的处理，比如设置过期，或者重新入列。如果时间片过长，可能还要做分段处理。
* 负载均衡。调用rebalance_tick()，传入idle标志位。

**try_to_wake_up()**

唤醒一个睡眠中的进程，主要工作有这么几部分：
1. 检查判断状态；
2. setcpu：选择合适的cpu，会考虑负载均衡
3. avtivate：设置activated，调用active_task()，加入调度队列
4. running：设置state为running
（关于睡眠、等待、唤醒、唤醒函数、进程数据结构等，需要整理为一个小专题）

进程从不可运行到能被调度，要经历什么？

首先，它的状态state，要从睡眠（可中断/不可中断/stopped等）到running（值为0），这个过程可能是信号，也可能是wakeup或者其他的。最终的操作就是在内核中，p->state = 0。

但是，它本身可以running，并不意味着它会被调度。还有一个工作，就是将它插入到和调度相关的数据结构中，在O(1)算法里，这就是通过调用active_task()完成的。它所做的工作，就是将一个已经running的task，重新计算prio，然后插入到rq包含到runlist中去。

而activated的值，则是在外面设置的——一般都是在由调用者根据自己的代码处境来设置。这个值在后续的调度算法中会有使用。

**recalc_task_prio()**

根据进程的睡眠时间等参数，重新计算进程的优先级。值得注意的是，进程的优先级会在以下位置可能被更改：
* 当进程被调度到，开始执行时；
* 当进程过期被调度时；
* 当进程从睡眠中被唤醒时。

进程在以下位置可能会执行recalc：
（太细节了，不想理了哈哈）

**schedule()**

调度函数所完成的工作大概是（具体可以参考书本）：
* 执行切换之前的准备工作：find_next()，如果运行队列为空，那就要考虑从其他cpu挪一些过来；最后如果实在没办法，就执行idle进程。还有用于各种调度管理的各种锁、参数检查、信息更新、时间保存等。
* 切换：context_switch()，先执行mm切换，再调用switch_to()。
* 善后工作。比如锁的处理之类的。


***
### cpu间的负载均衡

主要函数有：
rebalance_tick()
load_balance()
find_busiest_group()
find_busiest_queue()
move_tasks()
pull_task()

这是不太影响全局理解，但对于进程管理本身很重要的一个主题。现在的计算机几乎都是多处理/多核，尤其在大型服务器上，这应该是一项非常重要的工作。

负载均衡很好理解，不能让cpu们旱的旱死，涝的涝死，得让大家都差不多忙，从而达到效率最高。这在理论上也是可以的，因为只要我们持有了锁，不管在哪个cpu上，都可以倒腾所有cpu的rq，让他们变得均衡起来。我们只要解决以下的一下“小问题”：

* 如何计算cpu的负载因子，作为判定它忙不忙的依据？正在运行的进程数量？运行idle的时间？或者是其他的？
* 如何进行合理的互锁，防止竞争和死锁。
* 调度域的选择。对于超线程处理器，一个物理cpu可以对应多个逻辑cpu，是否要分层次，比如在一个物理cpu内部的均衡，以及各个物理cpu之间的均衡？
* 在什么位置、以何种频率触发均衡操作？当一个cpu无事可做的时候？还是一个cpu忙得头晕的时候？还是由单独的内核线程来执行？
* 其他的细节。移动的时候，优先级从高到低进行选择？一次移动多少？如何动态设置均衡间隔……

上面的几个函数基本就是回答了上面的这些问题，就不展开一个一个讨论了，如果真要了解看书看代码吧。

这个均衡算法的核心其实是调度域，它是这个算法能适用于各种处理器体系架构的基础。当然这种适用性也带来了它的问题——复杂性。

在需要的时候再深究吧，现在大概知道这个就行了：调度域的核心之一就是分层，在不同的层级上进行遍历处理。


***
### 调度中的进程

关于child-do-first，为什么我们增加到它runlist的前面，然后延迟调用schedule()，就能让child在前面执行呢？

这我们就必须了解schedule()的机制了。当我们调用schedule()时，会做一些什么工作？寻找合适的next，然后触发switch。找合适的next是很复杂的，如何得到一个能满足八方口味、公正与效率兼备、没有漏洞、运行时间还能短到O(1)完成的算法是很困难的，我们需要围绕这个算法组织数据结构，这就是进程调度的大题了。switch是另外一道大题，进程的上下文主要包括两部分，虚拟空间和硬件上下文，所以switch也主要是这两块。

那prev/next本身关于调度的信息更新呢？比如优先级、时间片、入列出列之类的？事实上，在schedule()中做得很少，对于next，如果它是刚从睡眠中苏醒过来的非实时进程，为了奖励它的睡眠贡献，会将它出列，重新计算优先级，再入列。这里就会用到activted，sleep_time等值。对于prev，不做任何事。

这可以吗？

这当然可以。当进程在运行时，它是一直位于runlist中的，事实上当我们调度到一个进程，如果它不是从睡眠中苏醒，我们根本就不会挪动它在runlist中的位置（这里的“挪动”，事实上也只是改变它们之间的连线，从而使得它们在链表中的逻辑位置挪动，但是从内核的角度来看，这个决定它访问顺序的逻辑位置才是重要的，而它位于内核空间的真实物理位置反而是次要的）。


***
### 进程的各种运行周期

所以，当一个进程主动睡眠，调用sleep时，
* 先将自己的state设置为不可中断睡眠，再直接调用schedule()；
* 在schedule()中，检查state状态，调用deactive_task()，完成出列。
* 在睡眠过程里，不会更改它的时间片、优先级等值。
* 当它被唤醒时，调用try_to_wake_up()，在其中将state设置为running，并调用active_task()，在其中调用recalc_task_prio，重新计算优先级。
* 此时只是加入了runlist，并没有真正执行。
* 被调度到，在schedule()中，发现它的activatd值，再次重新计算优先级。

(值得注意的是，进程睡眠或者终止，都是这个处理模式——在进入schedule()之前设置标志或者state，在内部判断state，并决定是否需要从运行队列删除掉prev进程）

当一个进程因为抢占（各种情况），set_need_sched()而被延迟调度时，
* 它不需要睡眠，所以依然是running，activated为0；它时间片还没用完，所以需要仍然处于active array中。
* 事实上，我们什么都不需要做，就让它留在原来的位置、原来的状态就好。它还是在它优先级的runlist里，还是留着它应该有的时间片，当抢占的高优先级进程运行完，再次调度时，它仍然是这个优先级里第一个被执行到的（事实上，它会被执行到，就说明它原来是在runlist的前面），直到它的时间片用完为止。所以抢占不会改变同一优先级里等待进程的执行顺序。
* 所以，当我们fork一个子进程，插入前面，重新调度时，会先执行子进程，再执行父进程，而为了不触发不要的写时复制，子进程应该在它的第一个时间片里，先把页表给换了，这个过程里不要触发什么fault，也就是不要进入睡眠。而如果是正常的将子进程入队，则会继续执行父进程，直到它的时间片耗尽，之后才会调度到子进程。

那么进程的时间片更新呢？
* 在tick里，会刷新进程的时间片，事实上，除了在fork()中的初始设置之外，这是我现在看到的唯一一个会改变time_slice的地方。
* 改变有几种：一是在每个回合递减；二是在用完后如何处理。
* 对于不同的进程，处理方式很不一样。比如对于FIFO策略，不需要管时间片；对于RR，时间片用完后恢复，但不会出列；对于交互式进程，可能也会继续留在队列里，会有各种判断；对于普通的批处理进程，则可能是重置时间片后放入过期队列。
* 但总之，在用完后会进行一些处理。但不管对于什么进程，它的优先级可能在睡眠唤醒中会不断重置，但是时间片只有在这里才会更改，虽然它是根据优先级来设置的。这很重要。
* 当在tick里发现current的时间片耗尽了，就会进行上面所说的各种处理，如果有需要，就延迟调用schedule()。此时原进程可能在过期队列里，有可能被重新放入了运行队列里。这都不影响。因为被调度的程序本来就可以在这些位置，这和睡眠是不同的。


***

### 时间片

**time_slice**

进程的时间片刷新在哪里？tick里，在时间片变为0后，才会被重置；其他情况下不管是睡眠、被抢占还是其他的，都不会更改。但是优先级有可能会被调整。在每一次重新调度的时候都会重新计算。

run_queue分为了active和过期两个队列，这两个队列的进程都是activated=0的。它们会一直存在于这两个队列里，只有当state变化时才会出队。所以在schedule()重新计算优先级后，是先出列再入列。也就是它们在执行时，本身是存在于active array的，但是不一定在队列头部。这并不影响它本身的执行，但是可能影响到下一次调度的结果。

当有进程从睡眠到就绪，它的activated会被设置。从内核线程中被唤醒，和从中断中被唤醒会设定不同的值，这样就可以在schedule()中根据这个值来执行不同的策略：如果由中断程序从可中断睡眠中唤醒，或者是从不可中断睡眠中唤醒，那么它更可能是一个交互进程。这样我们就给它加上更多的平均睡眠时间，从而计算得到更高的优先级，下次调度时更容易被调度到。

比如可能在某个中断处理函数中就会这样：
if(in_interrupt) p->activated = 2;

这里值得注意的是，当一个进程以某种方式被唤醒时（不管是wakeup还是信号还是其他的），并不一定会马上得到执行机会（除非内核允许抢占，它的优先级又很高）。很有可能它还会睡眠一段时间，这样等到它最终执行的时候，(now - p->timestamp)的值，其实是它睡眠加上等待的值。

***

**关于sleep_time/prio/bouns/sleep_avg等的计算**

挺绕的，不太想深究。大概的逻辑是：

进程的动态优先级prio=static_prio+bouns；
浮动bouns大概这样计算：bouns=（sleep_avg/max_sleep - 0.5)* max_bouns；
而sleep_avg的更新有赖于sleep_time和run_time，会在进程被调度时进行计算更新。大概就是这样。

***
**时间片初始化**

内核是不鼓励进程疯狂fork的，为了防止进程偷鸡，不断地fork子进程来偷取执行时间，所以当父进程fork时，会和子进程平分父进程的剩余时间。比如：

>n = current->time_slice;
>p->time_slice = (n+1)>>1;
>current->time_slice = n>>1;

如果父进程为偶数，两人平分；如果为奇数，则总是子进程多1；如果父进程tick=1，那它自己为变为0，触发延迟调度。


***
### 关于CFS

思想非常有意思，等弄完了2.6.11，有缘再会吧。


***
## 参考文章：进程调度

《深入理解Linux内核》

[Linux 调度器发展简述 （IBM社区）](https://www.ibm.com/developerworks/cn/linux/l-cn-scheduler/index.html)

[O(n)、O(1)和CFS （蜂窝科技社区）](http://www.wowotech.net/process_management/scheduler-history.html)


***