---
layout: post
title:  "Python：一些有趣的主题"
date:   2020-06-11 17:10:00 +0800
categories: 编程语言
tags: 编程语言 python
description: 
---

*  目录
{:toc}

***
## 一些主题的讨论

2018.03 

python还是好玩，选取一些有意思的主题讨论一下。参考：《Python核心编程》 

***
### 从函数式编程看生成器

生成器和流：

* 在函数式编程中，有接触到流stream的概念，它的核心思想是延迟计算。当我们创建一个流的时候，我们会得到一个函数。这个时候刚刚完成初始化的工作，即为这个函数准备好了执行的环境（闭包），但是它的code还没有开始运行。

* 对这个函数进行调用我们就可以得到一个pair，其一是一个值，其二是一个新的函数。对这个新的函数进行调用就可以得到下一个pair，依然是一个值和一个函数。当然每次得到的函数虽然code一样，但是其携带的闭包不同。

再来考虑python中的生成器。我们可以这样生成一个生成器：

```python
g = ( x**2 for x in range(5))

#它类似于：
def test():
    for x in range(5):
        yield x**2

g = test()

#如果使用Racket实现，那么就是类似于：

(define test
    (letrec ([f (lambda(x) (cons (* x x) (lambda() (f (+ x 1)))))])
(lambda() (f 0))))
(define t (test))

```

比较：

* 在python中，每次调用g.next()都可以得到下一个值，直到最后抛出结束的异常（在for循环中会自动捕捉这个异常并作为结束）。

* 在racket中，每次调用(t)得到pair p，然后(car p)得到值，(cdr p)得到下一个迭代的函数。如果把它封装成一个对象，那么我们可以为它定义一个next接口函数，大概做这些事情：
  * 调用其内的真正函数对象f，得到pair p
  * 修改f，使它指向(cdr p)
  * 返回(car p)

* 其中的思想就是，每一步都从一个直接求值的表达式e变成了一个接受0个参数的携带闭包的函数f，只有在调用时才进行一步求值，并返回下一个f。
 
* 最后的问题就是怎么将python的函数对象转换成流的？其实就是对于关键字yield的处理了。我没有看过python的源代码，但是可以猜测一下可能的处理方式：
  * 将一个函数的整个执行序列从每一个yield处断开，返回此时的值，以及接着开始执行的地址，并保留执行的栈帧不变。注意python和C++不同的是，函数的栈帧不是在函数完毕后自动释放的，而是由GC负责管理和回收的，所以将它的栈帧保留下来并不是一个新鲜的事情，就像所有闭包的做法一样。其实它本来就是一个闭包。
  * 或者说，yield只是引入的一个语法糖，python的这些生成器用递归+闭包也可以实现。
 
* 另外，可以用如下方式定义：n = yield r，那么，n就是之后调用f时需要传入的参数，类似于 (lambda (n) (….))，我们可以使用g.send(x)来启动生成器的下一轮求值。


***
### 函数参数传递 


关于函数参数传递：

* 对于C/C++参数都是传值的，如果要传递地址以修改原变量的值，必须要显式传指针或者引用。

* 对于C#，数据数据分为值类型和引用类型，对于值类型是值传递，对于引用类型是传递地址。但是在C#中，参数传递可以显式声明为ref传递。它和直接传递不同的是，它会在函数内部直接使用原对象。
  * 比如对于一个引用类型，在直接传递时，如果在函数内部修改它指向对象的值，这个改变会反映到所有指向它的引用；但是如果将这个引用指向另外一个对象（C#是松绑定），那就和原对象无关了。而ref传递则不同，如果将它指向另外一个对象，是直接让原来的引用所保存的地址改变了。 

* 而对于python，一切皆对象，所有的传递都是引用。 对于可变类型，如果在函数中修改对象的值，那么对象会被改变，而函数外的引用也是指向这个对象，所以会跟着改变。对于不可变类型，如果修改对象，那么会创建一个新的对象并指向它，在函数外的引用则指向原对象，不会改变。 

* 所以对于可变类型，它改变实际对象的值，展现出来的行为类似于引用传递；对于不可变类型，它修改引用中的地址，展现出来的行为类似于值传递。 
  
* 另外，因为python是动态类型，一个变量的类型不是固定的，可以通过反射机制查看，所以函数的参数不用指定类型，同样也不需要指定返回类型。如果函数没有返回值，则会返回一个None对象。 

*** 
###  关于引用计数和垃圾回收 

在C++/C#/Python中都有引用计数的概念，不同的是，C++中，一般是我们自己实现的，或者实现在智能指针内部的。而C#和Python中，则是内置于语言的GC中的。 引用计数的目的是实现资源的自动管理，在资源不再需要（没有人持有它）时自动地销毁。 

C++的资源管理：

* 这就需要吐槽一下C++了，对于在其中分配了资源的类，往往需要在构造函数中分配资源，在析构函数中释放资源，再重新定义copy函数和赋值运算符，在copy中执行深拷贝，在赋值运算符中进行自我赋值判定，释放原资源，分配新资源，还要考虑操作的异常安全性等。 
* 如果不这么做，那么在对象被拷贝时就会出现两者同时持有一份资源，两者的修改会互相影响；当其中一个对象被销毁时析构函数调用，资源被释放，另一个对象持有的资源不再有效，会导致访问越界。 

* 这种执行深拷贝的做法就是让对象虽然持有的是资源的引用，但是表现的行为是类值的——可以简单地相互拷贝和赋值，两者之间不会有任何的影响，它们持有的资源是独有的。 

***
C++资源共享：

* 另外的一种方式则是资源共享，对于比较大的数据结构，深拷贝往往需要比较长的时间和比较大的内存。那么允许多个对象共享同一份底层资源是个不错的选择，做法就是引用计数。在普通的构造函数中，分配资源，计数为1；在copy构造函数中增加计数；在析构函数中减少计数；在赋值运算符中中减少原资源的计数，增加新资源的计数。 在每一次减少计数时进行判定，如计数为0则free。 

* 使用这种方式时，所有的对象使用同一份底层资源，即对象中包含的指针指向同一个地址，在对象被销毁时，只减少引用计数而不是释放资源。 此时，整个对象的行为是类引用的，和指针类似。 

***
C++类值的资源共享：

* 如果要资源共享，又要让行为类值，那怎么办呢？ 
* 做法是写时复制。即在对象开始修改底层资源之前会进行判定，如果它不是资源的唯一拥有者，则执行深拷贝，让它单独拥有一份资源，使得它的修改动作不会影响到别人。 
  
***
C++智能指针：

* 每一次都要这样做无疑是一件非常繁琐、无趣又容易出错的事情，所以就有了智能指针。在智能指针的内部实现了资源的引用计数和自动管理。 

* 这里非常容易混淆的一个概念是，C++的概念是用类来管理资源，即在类的构造函数和析构函数里完成资源的分配和释放，利用对象的生存周期来自动释放，防止内存泄漏。这就需要把持有资源的指针作为一个数据成员保存在对象内，对象仅仅是一个容器。 

* 智能指针就是这个容器的一种泛型写法，它本身是一个对象，在它的内部保存有真正的数据指针，它的核心思想是就是用对象管理资源。只是把它做成了一个通用的模板，我们只需要传入指针的类型，即可自动生成外面的资源管理容器对象。 

***
C#/C++的不同：

* 这和C#/Python中的引用计数是有一些不同的，python中GC持有的是对象的引用计数，引用被销毁时计数减少，在计数为0时将对象销毁；而在C++中，是容器对象持有资源的计数，对象被销毁时计数减少，计数为0时释放资源。 

* 所以在C#中，一个对象可以有多个引用，但是它的析构函数只会执行一次，其中的资源释放（比如关闭某个连接）只会进行一次；而在C++中，每个容器对象被销毁时都会执行它的析构函数，只是只有最后一次才执行资源的释放。 

* C#中的对象相当于C++中的底层资源，而C#中的引用则类似于C++中的容器对象或者智能指针。GC将引用计数和销毁判定内置了，所在不再需要使用容器对象来管理资源，但同时它的模式固定下来了，不能再灵活地进行类值/类引用等乱七八糟的选择。 


***
### 关于动态类型的理解 

动态类型，声明变量时不需要声明其类型，变量的类型可以变化。 

* 首先，它是如何实现的？它的根本在于，万物皆为对象，一切对象皆为引用。我们可以持有的，操作的全部是引用，它仅仅是一张标签纸。它可以被贴在任意对象上，它是不确定的。我们唯一知道它指向的方式是在运行时，利用python的自省机制进行查询，而这个工作是在解释器内完成的。例如： myItem.cry()，myItem本身仅仅是一个地址，属性cry需要真实对象才能完成。当执行到这一条语句时，解释器会确定myItem指向的实际对象，并用它来调用cry，如果调用失败，则抛出异常。 
  
* 它的优点与缺点？ 
  
* 为什么C/C++不能实现动态类型 

***
### python的对象、类、类型 

python中，对象和类型的概念是非常容易混淆的。 

对象和类：

* 类是蓝图，对象是实体。类描述了一组对象所固有的特性和方法，从概念上来说，它是数据的抽象，将数据和操作融合在了一起，使之符合人类的操作习惯。 

* 从底层实现上来考虑，对于C++，类的代码会被编译后映射到代码区，对每一个数据成员和方法的访问会被转换为地址的偏移，其中，数据成员是对象地址的偏移，而方法是类代码地址的偏移。 当我们创建一个对象实例时，首先会分配一块足够大的空间，这个空间可能在堆上也可能在栈上，这个空间的首地址即是对象的地址。然后调用类的构造函数，将地址传入，构造函数对所有的成员进行初始化（如果没有显式定义，则执行默认初始化），在底层代码中，无非就是对每一个地址偏移做一个赋值操作，汇编没有变量和类型的概念。比如 
0x3ffaa832+8 1314 

* 类的概念可以理解为那一个代码块，类的地址即是代码块的首地址，所有的方法都对应着一个相对于首地址的偏移量，它被所有对象共用。但是因为C++的no bookkeeping哲学，所以在对象中并没有包含类的任何信息（除了虚表），这些志记的工作是由编译器完成的，编译器会根据变量的类型，将对于类方法的调用解析成某个地址函数的调用，所以在目标代码中没有任何高级特性，就是一个最普通的函数调用。 
  
* 在python中不一样。python的引用、对象、类中都有很多的bookkeeping。引用中记录了真实指向的对象；对象中记录了它所拥有的属性，它的类型；类中记录了它的属性； 在C++中，不可能只根据一个对象推断出它的类型，这个工作只能由编译器完成。但是在python中，可以在对象所保存的字段中读出它的类型，这种bookkeping即是动态语言反射机制的支持。 C++中，不需要记录类型的信息（编译器干了，它内部在进行分析时会生成很多的表），但是python需要，那么如何记录呢？最自然的方式就是将它变成一个对象，有着自己的属性和地址。比如对于一个我们自定义的类myClass和自定义方法test，它会在它拥有的属性中加上test，test是一个方法，它又拥有一系列的属性。之后在进行方法调用时，再进行层层查询。 
  
实例：

```python 
class myClass(object): 
    def test(): 
        pass 
mc = myClass() 
dir(mc) 
dir(myClass) 

#首先，mc可以访问myClass命名空间中的内容，所以在mc中也能看到test属性。其次，在mc和myClass中都有一些属性比如：__class__，__hash__，但是要注意，它们并不是同一个属性，比如： 

>>> mc.__class__ 
<class '__main__.myClass'> 
>>> myClass.__class__ 
<class 'type'> 

```

由此可见： 
* 在对象中bookkeeping了很多内容，其中就包括了它的class类型，并且对象实例可以访问类名称空间中定义的方法和类成员，但是类空间本身的默认属性比如__class__会被覆盖掉。 

* 类本身也是对象，所以有着和实例一样的默认属性，其class为type。 
  
其次，可以动态改变对象和类（类是一种特殊的type类型的对象）的属性，比如: 

```python
mc.num = 5 
myClass.test = 3 
mt = myClass() 
mc.next = mt 
```
现在mc拥有了自己的两个独立属性num和next，myClass的test属性不再是方法，而是int。值得注意的是： 

* 不管是mc，还是后面创建的mt，它们都是通过动态地查询myClass的属性而去访问test，所以 当改变了myClass.test属性后，它们对于test的访问也会跟着改变。这和静态语言在编译后就确定了类方法的代码地址是完全不一样的。 

* 正是因为对象和类型的属性可以动态地增加、删除、修改，所以每一次对于属性的访问都需要经过动态地查询，以确定属性的最新状态（可能被删除，也可能被更改，在查询之前是不可预知的）。这两者是相辅相成且相互统一的。对于静态语言，一个函数的执行和上下文语义基本没有关系，但在动态语言中，一个语句的执行和上下文关系十分密切。 

* type返回的是一个类型对象，而不只是字符串的描述，比如: type(mc).test 等效于 myClass.test。

***
### 内部类型 

* 代码对象 ：代码对象本身不包含任何执行环境信息， 它是用户自定义函数的核心， 在被执行时动态获得上下文。（事实上代码对象是函数的一个属性）一个函数除了有代码对象属性以外，还有一些其它函数必须的属性，包括函数名，文档字符串，默认参数，及全局命名空间等等。 
  
* 帧对象：帧对象表示 Python 的执行栈帧。 帧对象包含 Python 解释器在运行时所需要知道的所有信息。它的属性包括指向上一帧的链接，正在被执行的代码对象（参见上文），本地及全局名字空间字典以及当前指令等。每次函数调用产生一个新的帧，每一个帧对象都会相应创建一个 C 栈帧。用到帧对象的一个地方是跟踪记录对象。 
  
* 跟踪记录对象：当你的代码出错时， Python 就会引发一个异常。如果异常未被捕获和处理，解释器就会退出脚本运行，显示类似下面的诊断信息，当异常发生时，一个包含针对异常的栈跟踪信息的跟踪记录对象被创建。如果一个异常有自己的处理程序，处理程序就可以访问这个跟踪记录对象。 

```python
Traceback (innermost last): 
File "<stdin>", line N?, in ??? 
ErrorName: error reason 
```

*** 
### 动态语言和静态语言

（2020.6.11 回头来看，当时的理解粗糙而混乱，如果能加入一些上下文、静态环境、动态环境等概念的话，会顺畅很多；不过，保持原样吧：D）


* 重载隶属于静态多态性，实现方式是在编译期，由编译器根据函数的参数，对函数进行重命名，目的是功能相近的函数可以归一化处理，对于程序员来说它们的接口一致，方便处理。 python并不支持。从中可以扩展到动态/静态语言的思考。

* 静态语言中，编译器做了大量的簿记工作，这些工作不是某一个单独的句子，而是整个代码共同完成的。比如一个自定义的类有哪些方法，它们的地址是多少等。当我们执行某一句代码时，比如mc.test()，编译器先查询到mc的类型和地址，再由编译器保存的类型的相关定义表中，查询test是否存在，其地址在哪里。而这个表格是由之前的代码完成的。总的来说，在执行某一句代码时，它会用到很多之前的信息，而这些信息并不是真实地保存在语言内，而是在编译器中。 

* 而动态语言不一样，这些信息由语言自己保存，解释器只知道当前这一句代码，而没有簿记那些复杂的信息。解释器仅仅是根据这一个句子的语义，去执行某一件事情，而跟其他代码没有关系。各个句子之间没有相互影响。

* 比如mc.text()，对于静态语言，需要在编译器中查询test的地址，而这个地址是由其他代码决定的，当其他代码改动，它会跟着变化，那么mc.text()生成的机器码也会不一样。也即是说，编译器对于某一句源代码进行翻译生成的目标代码，是根据上下文语义来决定的，而不是单独地根据这一句。 

* 解释器则不然。它先查询mc，获得这个引用的地址，再查询它的test属性，最后调用，这些所有的bookkeeping都在语言内部，所以根据这一行代码执行的动作是一样的，其他代码会改变内存中的数据，但不会改变这一行代码本身的执行逻辑。 

* 所以，解释器是“逐行解释执行的”，而编译器是“整体编译”的。这中间的区别就在于bookkeeping的工作如果是在编译器中，那么一个语句生成的代码就必然跟上下文相关联。而如果bookkeeping在语言中，单个语句就是独立的、完备的。 


这其中有几个关键点： 

* 解释器往往可以当作一个黑箱，它逐行地解释并执行每一个语句，它和cpu融为一体，它对于每一个语句都执行并且输出。 

* 考虑一个简单的成员函数，对于静态语言来说，最后生成的可执行代码中，已经去掉了所有的bookkeeping工作，代码非常简单，就是一个简单的函数调用，将this传入。而对于动态语言来说，则要复杂得多，它要查询对象的类型，再查询类型的方法，获取方法的属性中的函数对象，再获取函数对象的属性代码对象，最后得到代码对象的地址，将self传入，开始执行。 

* 解释器的bookkeeping保存和编译器的保存到底有什么不一样？ 这个概念很难理解。 
  * 对于动态语言，mc.text()，可能被执行为： 
call object(id(mc)).[text].[func].[code]；
  * 对于静态语言，可能被执行为： call 0xff323ab3


bookkeeping：

* 在动态语言中，所有中间的数据结构都被保存在内存中，是状态的一部分。比如一个方法对象会包含func属性，它们跟我们自定义的属性一样，是对象的一部分，会被分配存储空间，甚至可以被修改和删除！所以我们可以在执行的代码里更改它们，比如修改text的指向，使得它从方法变成一个整数。此时在调用.[func]时会发现它没有这个属性，从而引发异常。 

* 在静态语言中，所有中间的数据结构是一个由编译器在编译期生成、保管、使用的静态表格，编译器根据源代码和表格生成目标代码，使得在目标代码里，不再含有任何的高级语言特性，它们没有了生命，没有属性，没有方法，它们只是冷冰冰的数据。所以我们没法在目标代码的运行时去更改中间的数据链——它们早就不存在了，在编译时已经被剥离了。它永远执行call 0xff323ab3。 

* 所以，静态语言的bookkeeping是在保存在编译器中，在编译器进行查询的，与目标代码无关的，与执行阶段无关的；而动态语言的bookkeeping是内置在语言内部，由对象自己保管的，可以在执行时动态地查询和修改的。前者只是编译器的一个用于转换的临时表格，在执行时已经不存在了，而后者真真切切地存在于内存中，是实体，随着程序的执行而变换，它们本身就是对象或者变量的一部分。 


这里我一直有个疑惑，静态语言的bookkeeping是由编译器保存的，那么动态语言的bookkeeping可能只是由解释器保存的，在执行时进行查询和修改，和前者没有什么本质的区别啊。这其中有两个区别： 

* 静态语言的bookkeeping是在编译期存在，而动态语言的bookkeeping在执行期间存在。所以前者不能在程序执行期间更改，而后者可以，而bookkeeping是如何保存的并不重要。解释器本来就可以当作是一个黑箱子嘛，里面是虚拟机也好，是一个编译器+cpu也好，具体实现我们完全可以不管。 

* 考虑一下如何保存，可以看到对于python来说，bookkeeping并不是维护一个在解释器中的表格，而是和对象的其他属性数据融为一体的。 

* 从抽象上来考虑的话，动态语言是在更高层次上运行代码。静态语言是将动态语言翻译成cpu能执行的低级语言；而解释器则赋予了cpu执行高级语言的能力（可以看作是对cpu封装，解释器本身就有虚拟机的概念，它可以执行的指令集），它使得我们可以专注于编程本身，这无疑是一种更加自然的表达方式。 

>什么是「动态语言」？这个概念其实没有一个明确的定义。基本上它是一个程度的度量。这个程度就是该语言的 runtime 到底使用多少 bookkeeping 数据。

* 动态语言为什么要一句一句地执行？因为它会改变内存中bookkeeping的状态。动态语言相当于增加了一层抽象层。对于静态语言，上下文代码会影响生成的目标代码，而程序执行期间不会改变bookkeeping，也不会改变目标代码。对于动态语言，上下文对于解释器的执行套路没有影响，但是程序执行期间会改变bookkeeping，进而影响最终给cpu跑的native code。一层是对解释器本身而言，一层是对底层cpu而言。如果一个语言把这些bookkeeping都放置在编译器，那它就是静态的。如果放在runtime，那它就可以认为是动态的。 

*** 
### 函数

（2020.6.11 如果可以加入metadata的概念，理解起来会更轻松一些）

**函数简介：**

* python中，函数参数不需要指定类型，返回值不需要指定类型，永远返回一个对象（可以是none对象或者元组对象）。 

* 函数在声明时还没有创建完成，所以不能在其内使用self。当创建完成后，它就成为了一个函数对象，可以增加和修改它的属性。 
在C++中，函数指针的类型会因为签名的不同而不同，而在python中，因为是动态类型，所以可以无差别地处理函数对象和其他对象，唯一的区别是函数对象有一个特别的属性__call__，它是可调用的。它有着自己的代码对象。

* 函数在被调用时创建一个栈帧，调用结束后销毁。而在使用闭包时，除非闭包的引用失效，否则外层函数的栈帧会一直存在。

* 使用不同的外层函数调用创建不同的闭包，它们的代码对象是一样的，但是持有的外层栈帧不同，所以在执行同样的逻辑会得到不同的结果。看起来就像——声明了多个不同的函数一样。 

***
**闭包：**

* 如果内部函数的定义包含了在外部函数里定义的对象的引用（这个对象甚至可以是在外部函数之外），内部函数会变成被称为闭包（closure）的特别之物。 高级闭包和装饰器的使用是非常有意思的。

* 首先，装饰器和闭包是有区别的。典型的装饰器语法如下： 

```python
def tsfunc(func): 
    def wrappedFunc(): 
        print '[%s] %s() called' (ctime(), func.__name__) 
        return func() 
return wrappedFunc 
```

* 装饰器接受一个函数对象为参数，将另外一个函数对象作为返回值。一般都会在其中调用原函数，使得基本功能得以保存，当然你也可以不调用。如果要使得上面的装饰器对任意参数的函数都适用，可以将wp的参数改成： 

```python
def wrappedFunc(*args,**kargs): 
    # code 
    return func(*args,**kargs)
```
当我们对一个函数使用装饰器时，比如： 

```python
@tsfunc
def add(x,y): 
    return x+y
```

实际过程如下：
* 先定义函数add，再调用add = tsfunc(add)，现在add变成了一个和之前参数相同，功能相同，但是会做一些额外事情的函数了。它实际上已经成为一个闭包，携带了函数tsfunc在上次调用时产生的栈帧。

* 我们也可以为tsfunc增加一些参数，这样在wp（也就是最后的add）中可以使用它们，也可以在tsfunc中执行一些动作，虽然它们只有在创建闭包时被执行一次。这里一定要明白的是，@tsfunc只是一种解释器能看懂的简写，在实际过程中是有函数调用的。 

接下来看一个比较复杂的例子： 

```python
def log8(when): 
    def log(f): 
        def wp(): 
            print('wp') 
            return f()
        print('log') 
        return wp 
    print('when') 
    return log 

@log8(1) 
def f8(): 
    print('f8') 
```

log8是带有参数的装饰器，它会使用一些参数去做一些事情，然后返回一个无参数的装饰器log，所以实际过程为log8(when)(f)，这里需要注意的有两点： 

* log8或者为带参数的装饰器，会返回一个实际的装饰器，或者直接是一个装饰器。不允许这么用： 

```python
def log8(): 
    def log(f): 
        def wp() 
            return f() 
        return wp 
    return log 

@log8 
def f8(): 
    print('hello')
```
* 这样使用时，因为log8没有带参数，会调用 f8 = log8(f8)，然后引发异常。 

* 在装饰器的包装函数中，是调用f()，而不是返回f。否则调用f8以后，会得到f8这个函数指针本身，而不会实现它原来的功能。 

* 可以利用带参数的装饰器做一些选择功能，比如在内部实现两个单独的装饰器，然后根据传入的参数进行选择：return {‘pre’:pre_logged,’post’:post_logged}[when]，如果这两个装饰器的代码有重复部分，还可以将它们提取出来，写成一个内嵌函数，然后在装饰器中调用。 

***
### 类/实例、类成员/实例成员 

* 在C++中，类的数据成员有普通的和静态的，成员函数也有普通的和静态的。静态的数据/方法可以被实例调用，也可以用类名调用，在静态的方法中，只能使用静态数据或者调用静态方法。 可以通俗地理解为，静态在程序的生命周期内存在，不依赖于实例的创建和销毁，当然它们也不能依赖于实例。它们属于类，被所用实例所共享。 

* 在python中，其中的概念更加清晰。 python中，没有静态和普通的区别，只有类和实例的区别。所有的成员和方法都可以分为两类：类或者实例。在类中定义的所有成员都是类成员，被所有实例共享；类中定义的方法均为类方法，被所有实例共享。 

* 你可能会问，实例方法呢？被你吃了吗？ 哪有什么实例方法，方法就是方法，实例方法仅仅是实例可以访问类的名称空间，可以访问类的属性，其中就包括可以调用的函数对象，也就是类的方法。当然实例有一个特权，当它调用类方法时，会默认将实例本身作为第一个参数传入。注意，这是在调用时发生的，而不是在定义时。以下是个有趣的例子： 

```python
class mc: 
    def mcf(num): #你说我要定义一个类方法，打印输入的数字 
        print(num) 

mi = mc() 
mc.mcf(5) #很好，输出了”5” 
mi.mcf(5) #TypeError: mcf() takes 1 positional argument but 2 were given 
mi.mcf() #<__main__.mc object at 0x02B74D70> 
```

你看它就是这么蠢。当实例调用类方法时，会不加分辨地将self作为第一参数传入。 现在回过头来考虑python中类和对象的实现:

* 当我们定义一个类mc时，解释器分配一块内存，构造一个名为mc类型为type的对象，如果什么都不做，mc的属性是空的。当我们定义类成员和方法时，会为它添加属性。比如上例中我们添加了属性mcf，它是一个函数对象。当然在mc中仅仅持有mcf的引用。

* 这个时候一个很有意思的事情来了。在python中，如果类定义了属性__call__，那么实例就是可调用的。也就是说，当一个对象后面跟了()时，解释器可能解释为： type(object).__call__(self)，mc是一个类，它是type对象。所以当我们调用mi = mc()，实际上可能执行了type.__call__(mc)，在这中间做了什么呢？

* 首先它创建一个对象: sm = mc.__new__()，万物皆对象嘛，刚出来时它还是赤果果的什么都没有，除了继承的基类object中定义的成员。

* 然后调用mc.__init__(sm)，对它进行初始化工作。这里其实容易陷入递归，比如怎么创建它的基类部分呢？暂时不管它，反正解释器会自动给它塞进一大堆的特殊属性，比如\__name__，\__class__之类的。

* 到此为止，对象创建完毕。重要的是，mi可以访问类mc名称空间中自定义的属性。（至于系统定义的属性，有些是隐藏的，有些会被名字覆盖掉，也许？）

* 从这样来看的话，python中，类和实例之间的耦合是非常松的，mc()仅仅是一个工厂函数，返回一个可以访问它属性的对象（有点闭包的意思？），且这个对象在调用方法时会进行默认传参。除此之外，类对于实例不再有任何限制，它们是彼此独立的。类和对象都可以增加/更改/删除自己的属性，都拥着着自己的名称空间。 

* 这里特别地提一下，内建类型比如int，没有__dict__属性，也不能给它添加自定义属性。 

* 字典位于实例的“心脏”。__dict__属性跟踪所有实例属性。举例来说，你有一个实例inst，它有一个属性foo，那使用inst.foo 来访问它与使用 inst.__dict__['foo']来访问是一致的。 

* 或者说一个对象的属性更改，仅仅是修改其__dict__字典，而对象的内存空间中持有的字典的引用是不变的。所以不管是什么类型的对象，不管这个对象的属性怎么改变，它的框架不会变，它需要的内存不会变——那是由object/元对象框架决定的。属性链会递归，直到下降为内置类型：数字，字符串，元组，列表，字典。内置类型不再有__dict__属性，它们是递归的终结条件。完美！

* 给定类 X 和实例 x，如果在X中定义了属性foo，x.foo由__getattribute__()转化成：type(x).__dict__['foo'].__get__(x, type(x))，描述符可以实现与C#类似的属性，可以完成对某一个属性的访问权限的控制，比如只读。 

*** 
### 描述符 

还没看懂 - -。 

*** 
### 正则表达式Re 

我唯一学到的是，如果不实际使用它，记住一百次就会忘记一百次……

***
### 类和实例的属性


__dict__和dir()、__dir__()：

* 首先，\__dict__是一个字典，存储的是键值对，而dir()返回的是一个list，里面只有key。
* 其次，\__dict__是dir的一个子集。
* 对于实例对象，\__dict__只包含实例属性，而不包含类的属性。
* 对于类，\__dict__只包含类自身的属性，而不包含其父类属性。
* 而dir()会返回其所能访问到的所有属性，会包含__dict__的所有keys。


例如：

```python
class c(object):
    def __init__(self):
        self.x = 1
    def test(self):
        self.y = 0
m = c()

>>>c.__dict__
mappingproxy({'__dict__': <attribute '__dict__' of 'c' objects>,
              '__doc__': None,
              '__init__': <function __main__.c.__init__>,
              '__module__': '__main__',
              '__weakref__': <attribute '__weakref__' of 'c' objects>,
              'test': <function __main__.c.test>})

>>>m.__dict__
{‘x’:1}

>>>dir(c)
['__class__',
 '__delattr__',
 '__dict__',
 '__dir__',
 '__doc__',
 '__eq__',
 '__format__',
 '__ge__',
 '__getattribute__',
 '__gt__',
 '__hash__',
 '__init__',
 '__init_subclass__',
 '__le__',
 '__lt__',
 '__module__',
 '__ne__',
 '__new__',
 '__reduce__',
 '__reduce_ex__',
 '__repr__',
 '__setattr__',
 '__sizeof__',
 '__str__',
 '__subclasshook__',
 '__weakref__',
 'test']
 
```
而dir(m)只比dir(c)多了一个x。

***
### 函数作用域

关于函数作用域的一个有意思的例子：

```python
name = ‘xixi’
def f1():
    print(name)
def f2():
    name = ‘hehe’
    f1()
f2()
```

会打印什么呢？

答案是xixi，因为python中函数遵循的是词法域（也称为静态域），函数所能访问的作用域是在创建时决定的，即f1中的name会一直指向全局变量那个name。

现在我们改变一下：

```python
name = ‘xixi’
def f1():
    print(name)
 
def f2():
    global name
    name = ‘hehe’
    f1()

f2()
```

那么就会输出hehe了。

我们还可以这样改：

```python
name = ‘xixi’
def f2():
    def f1():
         print(name)
    name = ‘hehe’
    f1()
f2()
```

那么结果仍然是hehe，注意在这个例子中，甚至于f1定义在对name的更改之前，这在python中并不影响，因为会先建立f2的局部作用域，绑定了局部变量name，再创建函数f1。

所以如果这样：

```python
name = ‘xixi’
def f2():
    def f1():
         print(name)
    f1()
    name = ‘hehe’
f2()
```
此时，name是引用的局部变量中的name，但是它还没有被赋值，就会报引用了未赋值的自由变量的错误。

有意思吧~~

***
### 协程

**如何处理阻塞事件**

首先，考虑一个实际的逻辑流程。需要在按钮点击事件中执行一系列文件的下载，这些文件的下载非常耗费时间。

* 第一种方式：直接调用阻塞式download()，毫无疑问，这是一个漫长的过程，主界面卡死了。

```c#
for file in files:
    download(file)
```

* 第二种方式：对download进行包装，编程非阻塞函数download2，具体做法无非是在download2中新开一个线程执行download，等它结束后再触发一个完成事件。但是如果有一堆文件要排队下载呢，就不好处理了。

```c#
void download2(file,fun1){
   var t = thread( () => {download(file);fun1();})
   t.start();
}

void fun1(){
   file = files[i++]
   download2(file,fun1)
}
```

fun1为下载完成后的回调函数，在C#中一般封装为事件或者委托。当然用异步回调写循环是一件极为操蛋的事情，我上面都是瞎写的，明白意思就好。据说在C#中可以给lambda命名，然后让他自己递归了。那写起来就会很舒服了。

用异步回调的方式写时，大概就是主线程调用一个工作线程去执行一个耗时任务，并注册完成事件（或者说完成的回调函数），让工作线程在跑完后通知主线程。所以称为异步回调方式。因为异步执行嘛，不回调主线程怎么知道你跑完了。
     
* 第三种方式：协程，“允许你用同步的方式写异步代码。”

```C#
void downloads(files){
   foreach file in files{
         await Taskdownload(file)
   }
}
```

***
**协程**

* 协程的本质是用户态的线程，不同的逻辑流之间的切换在用户空间中实现，而不用操作系统参与。因为没有陷入内核，没有线程/进程调度，没有上下文切换，所以切换的效率非常高。但它的本质还是多个独立的逻辑流之间的切换，它可以看作是用户态的轻量级线程。

* 那么它怎么实现的呢？操作系统在进行线程调度的时候会保存堆栈等上下文信息，以使得调回来时从上次中断的位置执行。这就是协程的特点，它的函数在每次进入时，都会回到上次退出时的状态，而不是普通函数调用时一样会重置。可以将它粗暴地理解为每一个协程都有一个独立的堆栈，而在协程执行到yield时会返回，但是堆栈不会被清空，而是会被保存。

* 所以协程可以随时中断，又可以随时恢复。当我们执行一个耗时的IO操作时，就可以将它设置为yield的断点，直接返回而不是阻塞在那里，等到IO完成了，在IO中断中再次进入函数，并从原来中断的位置继续往下执行。大概就是这样：

```python
@asyncio.coroutine
def hello():
    print('Hello world! (%s)' % threading.currentThread())
    yield from asyncio.sleep(1)
    print('Hello again! (%s)' % threading.currentThread())
 
loop = asyncio.get_event_loop()
tasks = [hello(), hello()]
loop.run_until_complete(asyncio.wait(tasks))
loop.close()
``` 
相关说明：
* asyncio.coroutine是一个装饰器，会在里面对hello进行初始化工作，将它注册为一个异步IO协程等。

* 把tasks放到消息循环中，当第一个hello执行到yield from asyncio.sleep(1)时，会直接返回，开始执行第二个hello，同样也执行到这个位置后返回，进入消息循环等待下一个任务。

* 这里要特别注意sleep同样是一个协程，它和普通的sleep是不一样的。普通的sleep是线程挂起，而这个sleep是在其内部的yield处返回，再在中断来临时继续往下执行。

* 当sleep返回时，hello继续往下执行，并且会从之前中断的位置开始。

* 其中一定要注意的是，普通的IO操作是阻塞的，所以要将它们封装成Task。然后以写同步代码的方式来实现异步调用。所以这个包就叫异步IO。python中有很多第三方的异步IO库，比如aiohttp就是基于asyncio实现的HTTP框架，同样aiomysql是MySQL的异步驱动程序。



***
**Python中的协程**

coroutine和generator有一些关联，同时有很大的区别。generator是生成一系列的值，而coroutine是传递一系列的值。

```python
def acc():
      sum = 0
      while(1)
            next = (yield)
            if next is None:
                 return sum
      sum += next
 
def compute(sums):
      while True:
           sum = yield from acc()
           sums.append(sum)
sums = []
com = compute(sums)
com.send(None)
for I in range(5):
      com.send(I)
com.send(None)
for I in range(10):
      com.send(I)
com.send(None)     
```

几个注意点：
* 一个协程类似于一个子线程逻辑流，所以要添加while循环，否则程序执行到return或者函数结尾，就会触发stopIteration错误。
* 从上层传入的值能透明地传递下去，而在compute中，执行逻辑将停留在yield from语句，直至acc返回，触发stopIteration异常，此时将异常的一个参数的值赋给sum，继续执行后面的语句。
* 所以，从整体来看，send()似乎穿过了中间层，直接分发到了末端。所以协程可以用作数据或者事件的分发。
* 另外，当调用com = compute(sums)的时候，和函数调用不同的是，逻辑并不开始执行。并且第一个调用必须传入None，它会调用next()，否则会报错。

***
**第二次总结**

协程本质上是用户态下的线程。它支持并发的逻辑流，又没有进程或者线程切换是陷入内核的额外开销。也就是说它的线程调度是由进程自己控制的，用程序自己实现的，期间没有规定的时间片，没有时钟阻塞。

这其中需要特别注意的是，

* 首先协程的切换是靠逻辑流本身的自觉，是非抢占式的。如果是OS下的线程是一群嗷嗷待哺的流氓的话，协程就是一群很有分度的绅士了。
* 其次，肯定会有一个调度器。它可能是一个队列或者其他什么东西，但肯定存在。
* 最后，IO必须是非阻塞的（我们经常会称为异步的），否则等待IO的逻辑流会把整个线程都堵死。

再来梳理一下Python中的协程。
* 首先是生成器。生成器可以看做是能保存状态的函数，每次进入时都能从上次退出的状态继续开始执行。我们暂时不管它的实现方式是一个独立的栈还是怎么的，这个生成器从概念上来说是一个可以中断的逻辑流。如果把整个函数过程看做是一个逻辑流，这个逻辑流可以在特定的位置中断，并继续。而协程就是基于生成器实现的。

比如考虑下面的协程：

```python
async def test():
      console.write(‘start’)
      await asyncio.sleep(1)
      console.write(‘continue’)
      return ‘ok’
```

当这个协程被调用时，到达await语句后，函数就返回了，转而执行线程调度池里的下一个逻辑流。而当异步操作sleep返回时，会将test重新加入到调度池，在某个时间起继续执行，并且可以通过send将sleep的返回值传入，比如read()的data。test继续执行，当它return时又会将调用它的协程加入调度池，比如xxx.send(‘ok’)。

所以如果是一个几层的嵌套：

```python
async def fun1():
      dosomething11()
      await someAsyncIO()
      dosomething12()
      return x
 
async def fun2():
      dosomething21()
      temp = await fun1()
      dosomething22(temp)
      return x
 
async def fun3():
      dosomething31()
      temp = await fun2()
      dosomething32(temp)
      return x
``` 
另外我们需要一个loop，loop.run([fun3(),task1,task2….])。那么顺序就会是：
* dosomething31()，dosomething21()，dosomething11()，
* AsyncIO()
* dosomething12()，dosomething22()，dosomething32()
 
再来感受一下异步加回调的写法：

```python
app.get('/test', function (req, res) {
    fs.readFile('/file1', function (err, data) {
        if (err) {
            res.status(500).send('read file1 error');
        }
        fs.readFile('/file2', function (err, data) {
            if (err) {
                res.status(500).send('read file2 error');
            }
            res.type('text/plain');
            res.send(data);
        });
    });
});

```
而用协程时：

```python
(req,res) = await app.get(‘/test’)
(err,data) = await fs.readFile(‘/file1’)
if (err) {
res.status(500).send('read file1 error');
}
(err2,data2) = await fs.readFile('/file2')
if (err) {
res.status(500).send('read file2 error');
}
res.type('text/plain');
res.send(data);
``` 
直接用写同步代码的逻辑一路写下来，逻辑流会自动地处理暂停与继续。而异步回调方式需要在调用的第一个函数的回调函数里写入所有的后续逻辑，层层嵌套，即如果要做事情1,2,3,4,5，那么就需要：

```python
4.StopEvent = 5
3.StopEvent=4
2.StopEvent =3
1.StopEvent=2
```
然后开始1。
 
而协程的方式是：

```python
1
2
3
4
5
```
优美！
 
***
**第三次总结**

首先，线程的概念是什么？逻辑流。

线程的切换就是逻辑流的切换。它的上下文包括寄存器，栈等等。我们在一个线程里进行普通的函数调用时，没有线程的切换。它们是顺序的，放置在同一个堆栈中的。

协程不是普通的函数调用。它是一种子线程。协程之间不是调用的关系，而是不同的逻辑流。所以同样，它的切换也会有上下文的切换，比如寄存器和堆栈。

那它和线程的区别呢？

* 首先，效率。线程的切换需要陷入内核。因为线程是抢占式的，所以必须依赖于时钟和中断来进行调度，这必须由操作系统实现。而协程是非抢占式的，自愿退出的，所以它完全可以在用户态下实现，这能使得当有大量的子线程存在时，不用频繁地陷入内核，能提高效率。
* 其次，共享变量的互锁。在多线程中，必须对共享变量加锁，以防止两个线程同时读/写它；在协程中则不用，因为协程的切换掌握在自己手中，所以我明确地知道在我处理完，申请退出之前，不会有其他子线程来抢占，所以也不会发生资源的竞争。
* 所以，总的来说，协程就是用户态下的子线程，由用户自己实现逻辑流的调度。而且其中的切换是非抢占式的。

***
### 编程语言和编程思想

语言只是用来表达思想的。用语言写出来的程序就是思想的表述。

为什么会有不同的编程语言？因为编程思想有很多，甚至在某些地方有多个岔路口多个选择，而编程语言很多时候体现了某种编程思想，或者说内置了实现某种编程思想的语法。比如JAVA和C++的面向对象，Haskell的函数式编程。

所以学习不同的编程语言是有意义的。通过分析某个编程语言出线的原因，发展的脉络，具有的优势，存在的意义，我们可以大致把握到它所体现的思想，那是本质的东西。

当然，这也要求我们在学习语言时，应着眼于它内在的思想，而不是语法的细节。那些只是为了实现思想所做的具体动作，而思想是抽象。

***
**函数和对象**

在C++中，除了函数之外，还有其他的可调用对象，比如lambda表达式，比如函数指针，比如函数对象。对于调用者来说，它们是一致的。它们接受参数，返回相应的值，在中间进行处理。

首先可以利用函数对象对已经存在的函数进行包装，比如原来的函数需要两个参数，我们可以包装成只需要一个输入参数。

其中一种方式是在类中重载函数调用运算符，格式如下：
int operator()(int val) const{
    /* code */
}
当使用这种函数对象时，本质上还是调用的函数，只是中间进行了一次匹配，最终调用的是类的成员函数。

通过底层实现我们来思考一下函数。

* 函数是为了提高代码块的复用率而引入的，函数的签名是一种约定，确定了调用者和被调用者必须遵循的接口。同样，函数实现了良好的封装，使得调用者不用直到内在的处理细节，而只需要关注接口。

* 在所有的处理中，总会有着数据以及对这些数据执行的操作。在函数中，数据可以有全局的，也可以有局部的。如果是值传递，传入的参数都会被初始化为一个局部变量，包括指针对象。如果是引用传递，则会直接操作原始对象本身。

* 这些局部对象存放在栈里。操作则存放在代码区。当我们调用一个函数时，通过将指针指向函数的起始，开始执行函数体内的代码。包括读取寄存器中的参数，更新堆栈，进行相关计算，将结果放置在寄存器中，最后返回，将控制交还给调用者。

* 函数的本质上是由数据和在数据上执行的操作组成，如果将它看成一个整体的对象，那么它所有的实例共享操作，即存放在代码区的操作代码，而所有的实例都有着自己的数据，在C++/C中是存放在堆栈上的栈帧。

* 在Python/JS中，因为函数的栈帧不再处在堆栈上，而是在对于每一个函数的调用，在堆上分配一个独立的栈帧，由GC负责管理，所以可以将函数视为对象进行处理，同时因为内部函数会保留有外部函数栈帧的引用，使得它不会被回收，从而使得在内部函数的生命周期内外部作用域的数据一直有效，内部函数在使用上完全等价于函数，它即是闭包。

* 在python中，在任意位置都可以更改函数对象的属性（使用成员运算访问符），即函数本身就是一个对象，除开操作代码外，它还拥有自己的数据成员，这些属性对所有函数对象的实例都是共享的。

***
**类的概念**

首先，在机器看来，是没有类这个东西的，对于它们而言只有存储的数据和可执行的代码。类的概念是人为构造的，是为了将人类的世界观映射到代码的世界里，对数据和代码进行抽象和封装，将程序组织成方便人类理解的模块，从而方便组织以及维护。

以C++为例。

* 源文件在编译时会被翻译成可执行文件，其中的数据和代码会被映射到不同的内存区域（这一部分工作由编译器和链接器完成）。

* 对于C程序来说，它们的划分是非常清晰的。全局变量和静态变量被分配到数据区，有着固定的地址，存在于程序的整个生命周期。函数被分配到代码区，其中的局部变量随着函数的调用，会在栈中动态地生成和销毁。（对于new，返回的对象的引用也是存放在栈中的局部变量）

* 对于一个定义了类的cpp文件，在它之内的所有数据都不是顶层代码，所以也不是全局变量。只有它的静态成员函数会被映射到数据区，从此独此一份，有着固定的地址。而它的整个代码块会被映射到代码区，里面包含着一系列的函数，根据访问权限有着不同的作用域。

* 当我们创建一个类的实例时，首先会new一块足够大的空间，然后调用类的构造函数。并且会隐式传递地址给它，这个地址就是用来存放实例对象数据成员的地址，也就是C++中的this指针，python中的self对象，只是传给构造函数的内存块中（编译器知道类有多大，所以会分配一个足够大的内存块给它，而且对于每一个数据成员，都定义了它相对于this指针的偏移量），还是空的或者说未定义的。构造函数在执行函数体前会做很多的工作，比如初始化所有的数据成员（所以是以类中声明的顺序进行初始化），比如对于存在虚函数的类，找到一个合适的位置放置虚函数表的引用等等。当构造函数执行完毕时，这个内存块中已经是满满的干货了，化身为有血有肉有数据的实例对象，可以在它们身上执行各种花式操作了。

* 之后调用其他的成员函数时，其实仅仅是最普通的函数调用，在底层是同一个世界同一个call，仅仅是在第一个参数%rax中塞入了this指针，使得在这个函数中可以使用实例对象的数据成员（就是this指针加一个编译器知道的偏移量），当然访问某一个数据时，编译器会自动把成员名字映射成相对于this指针的地址偏移。

* 在这里另外需要提到的一点是，类的封装，数据的不可见性等等，都是在编译器层面或者解释器层面的语法分析，对于机器而言你给它一个地址它就跑去找数据，没有任何的限制。

* 当我们使用C语言实现类时，所用的思路和C++中的实现是一致的。首先分配好一个数据块（struct），里面是没有经过初始化的各个数据成员，然后将这个数据块的指针传给构造函数，在构造函数里对数据成员进行初始化，成员函数的定义也仅仅是包含了this指针的函数。当然因为编译器的关系，访问权限是没办法定义private了。

* 对于python，这种关系是更加显而易见的。当我们导入一个类时，会执行所有的顶层代码，其中包括一些数据成员，即类数据，被所有实例对象所共用。当创建一个类的实例对象时，会先创建一个对象，再调用__init__函数，在其中对实例数据进行相关初始化。

* 所以，类是什么？类只是我们通过一些手段，人为地将数据和代码进行绑定（使用的方式是隐式传递this指针），以完成合理地抽象与封装，使得其概念符合人的思考方式，使得它的数据对外不可见，使得代码默认就可以访问相关的数据，最后构造出来一个整体的概念。仅此而已啊。

* 在python中，需要做更多的工作。它不再有构造函数（注意__init__不是构造函数，而是在构造完成后自动调用），类本身就是一个可调用对象。在《python核心编程》中，对于对象的解释是这样的：

>对象——数据和功能的默认抽象。

***
**面向对象思想**

《python核心编程》中对于面向对象思想的解释：

* 面向对象编程为数据和逻辑相分离的结构化和过程化编程添加了新的活力。面向对象编程支持将特定的行为、特性以及和/或功能与它们要处理或所代表的数据结合在一起。Python的面向对象的特性是与生俱来的。
* 对象——数据和功能的默认抽象。
* 然而，如果我们能对数据加上动作呢？如果我们所创建和编写的数据片段，是真实生活中实体的模型，内嵌数据体和动作呢？如果我们能通过一系列已定义的接口(又称存取函数集合)访问数据属性，像自动取款机卡或能访问你的银行帐号的个人支票，我们就有了一个“对象”系统，从大的方面来看，每一个对象既可以与自身进行交互，也可以与其它对象进行交互。
* 面向对象编程踩上了进化的步伐， 增强了结构化编程，实现了数据与动作的融合：数据层和逻辑层现在由一个可用以创建这些对象的简单抽象层来描述。现实世界中的问题和实体完全暴露了本质，从中提供的一种抽象，可以用来进行相似编码，或者编入能与系统中对象进行交互的对象中。类提供了这样一些对象的定义，实例即是这些定义的实现。二者对面向对象设计（object-oriented design，OOD）来说都是重要的，OOD 仅意味来创建你采用面向对象方式架构来创建系统。
* 考虑用OOD来工作的一个最重要的原因，在于它直接提供建模和解决现实世界问题和情形的途径。

* 抽象/实现：抽象指对现实世界问题和实体的本质表现，行为和特征建模，建立一个相关的子集，可以用于描绘程序结构，从而实现这种模型。抽象不仅包括这种模型的数据属性，还定义了这些数据的接口。对某种抽象的实现就是对此数据及与之相关接口的现实化(realization)。现实化这个过程对于客户程序应当是透明而且无关的。

* 封装/接口：封装描述了对数据/信息进行隐藏的观念，它对数据属性提供接口和访问函数。通过任何客户端直接对数据的访问，无视接口，与封装性都是背道而驰的，除非程序员允许这些操作。作为实现的一部分，客户端根本就不需要知道在封装之后，数据属性是如何组织的。在Python中，所有的类属性都是公开的，但名字可能被“混淆”了，以阻止未经授权的访问，但仅此而已，再没有其他预防措施了。这就需要在设计时，对数据提供相应的接口，以免客户程序通过不规范的操作来存取封装的数据属性。

* 类是一种数据结构，我们可以用它来定义对象，后者把数据值和行为特性融合在一起。类是现实世界的抽象的实体以编程形式出现。实例是这些对象的具体化。可以类比一下，类是蓝图或者模型，用来产生真实的物体（实例）。

* 总结：所以，类是什么？类只是我们通过一些手段，人为地将数据和代码进行绑定（使用的方式是隐式传递this指针），以完成合理地抽象与封装，使得其概念符合人的思考方式，使得它的数据对外不可见，使得代码默认就可以访问相关的数据，最后构造出来一个整体的概念。仅此而已啊。

***
《人月神话》中关于面向对象的说明：

* 达特茅斯的 Mark Sherman 提出，必须仔细地区别两个不同的概念： 抽象数据类型和层次化类型， 后者也被称为类（class）。 抽象数据类型的概念是指对象类型应该通过一个名称、 一系列合适的值和操作来定义， 而不是理应被隐藏的存储结构。 抽象数据类型的例子是 Ada 包（以及私有类型）和 Modula 的模块。

* 层次化类型，如 Simula-67 的类， 是允许定义可以被后续子类型精化的通用接口。这两个概念是互不相干的——可以只有层次化， 没有数据隐藏； 也可能是只有数据隐藏， 而没有层次化。两种概念都体现了软件开发领域的进步。

* 它们的出现都消除了开发过程中的非本质困难，允许设计人员表达自己设计的内在特性， 而不需要表达大量句法上的内容， 这些内容并没有添加什么新的信息。 对于抽象数据类型和层次化类型， 它们都是解决了高级别的次要困难和允许采用较高层次的表现形式来表达设计。

* Parnas的模块信息隐藏定义是研究项目中的第一步，它是面向对象编程的鼻祖。Parnas把模块定义成拥有自身数据模型和自身操作集的软件实体。它的数据仅仅能通过它自己的操作来访问。第二步是若干思想家的贡献：把Parnas模块提升到抽象数据类型，从中可以派生出很多对象。 抽象数据类型提供了一种思考和指明模块接口的统一方式， 以及容易保证实施的类型规范化访问方法。第三步，面向对象编程引入了一个强有力的概念——继承， 即类（数据）默认获得继承层次中祖先的属性 。


***
**总结：**

类和封装的思想来源于信息隐藏。最开始的时候是以模块为单位，将数据和操作集成，使得只有模块中间的操作可以访问内部数据，将它们组合成一个整体。而信息隐藏的目的是为了能更好的沟通——或者说最开始的时候信息隐藏的对象正是程序员本身，定义了模块以后，程序员不需要知道其他人所实现模块的全部细节，仅仅需要知道接口。

高级语言中，将封装的思想内置到语言本身，即为类。类有自己的命名空间，数据只能被自己的成员函数访问。

再后来，为了代码的复用，又出线了新的概念——继承。需要区分开，封装是是抽象数据类型，而继承是层次化类型。

